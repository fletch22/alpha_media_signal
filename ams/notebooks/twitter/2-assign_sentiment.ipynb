{
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "\n",
     "from pathlib import Path\n",
     "\n",
     "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
     "\n",
     "from ams.config import constants\n",
     "from ams.services import file_services\n",
     "import pandas as pd\n",
     "import time\n",
     "import dask\n",
     "import dask.dataframe as dd\n",
     "from dask.dataframe import from_pandas\n",
     "import numpy as np\n",
     "\n",
     "from typing import List\n",
     "\n",
     "\n",
     "input_path = Path(constants.TWITTER_OUTPUT_RAW_PATH, \"deduped\", \"main\")\n",
     "files = file_services.list_files(str(input_path), ends_with=\".parquet\", use_dir_recursion=True)\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "analyzer = SentimentIntensityAnalyzer()\n",
     "\n",
     "def add_senti(text) -> List[str]:\n",
     "    result = analyzer.polarity_scores(text)\n",
     "    return [result[\"neg\"], result[\"neu\"], result[\"pos\"], result[\"compound\"]]\n",
     "\n",
     "parent = Path(constants.TWITTER_OUTPUT_RAW_PATH, 'sent_drop', \"main\")\n",
     "\n",
     "\n",
     "\n",
     "%%time\n",
     "\n",
     "\n",
     "dask.config.set(scheduler='processes')\n",
     "\n",
     "all_ddf = []\n",
     "for f in files:\n",
     "    pdf = pd.read_parquet(f)\n",
     "    \n",
     "    split_dfs = np.array_split(pdf, 12)\n",
     "    del pdf\n",
     "    \n",
     "    for sdf in split_dfs:\n",
     "        print(\"Converting Pandas dataframe to Dask DF ...\")\n",
     "        ddf = from_pandas(sdf, npartitions=27)\n",
     "\n",
     "        ddf = ddf.assign(sent_list = ddf.nlp_text.map(lambda x: add_senti(x)))\n",
     "        ddf = ddf.assign(f22_sentiment_neg = ddf.sent_list.map(lambda x: x[0]))\n",
     "        ddf = ddf.assign(f22_sentiment_neu = ddf.sent_list.map(lambda x: x[1]))\n",
     "        ddf = ddf.assign(f22_sentiment_pos = ddf.sent_list.map(lambda x: x[2]))\n",
     "        ddf = ddf.assign(f22_sentiment_compound = ddf.sent_list.map(lambda x: x[-1]))\n",
     "        ddf.drop(\"sent_list\", axis=1)\n",
     "\n",
     "        start = time.time()\n",
     "        ddf.compute()\n",
     "        end = time.time()\n",
     "\n",
     "        sent_drop_path = file_services.create_unique_folder_name(parent, prefix=\"sd\")\n",
     "        ddf.to_parquet(path=str(sent_drop_path), engine=\"pyarrow\", compression=\"snappy\")\n",
     "    \n",
     "#     print(\"Elapsed: \" + str(end - start))\n",
     "#     all_ddf.append(ddf)\n",
     "\n",
     "# print(\"Concatenating Dask DFs ...\")\n",
     "# ddf = dd.concat(all_ddf,axis=0)\n",
     "# ddf.columns\n",
     "\n",
     "\n",
     "\n",
     "\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}