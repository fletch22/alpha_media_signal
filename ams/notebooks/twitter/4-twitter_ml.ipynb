{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "paths_to_add = ['/home/jovyan/work', '/home/jupyter/alpha_media_signal']\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ams.services.equities.EquityFundaDimension import EquityFundaDimension\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "\n",
    "from ams.config import constants\n",
    "from ams.services import twitter_service\n",
    "from ams.services import ticker_service\n",
    "\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "from ams.services import file_services\n",
    "from typing import List\n",
    "from ams.notebooks.twitter.twitter_ml_utils import WorkflowMode\n",
    "from ams.notebooks.twitter import twitter_ml_utils\n",
    "from ams.utils import date_utils\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from statistics import mean\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "paths_to_add = ['/home/jovyan/work', '/home/jupyter/alpha_media_signal']\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ams.config import constants, logger_factory\n",
    "from ams.services import twitter_service\n",
    "from ams.services import ticker_service\n",
    "\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from ams.notebooks.twitter.twitter_ml_utils import WorkflowMode\n",
    "from ams.notebooks.twitter import twitter_ml_utils\n",
    "from ams.utils import date_utils\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "logger = logger_factory.create(__name__)\n",
    "\n",
    "\n",
    "def process(df_twitter_raw: pd.DataFrame, predict_date_str: str, workflow_mode: WorkflowMode, num_hold_days: int):\n",
    "    cat_uniques = None\n",
    "    model_xgb = None\n",
    "\n",
    "    dt = date_utils.parse_std_datestring(predict_date_str)\n",
    "    if date_utils.is_stock_market_closed(dt):\n",
    "        logger.info(\"No can do. Market closed.\")\n",
    "        return False\n",
    "\n",
    "    if workflow_mode is WorkflowMode.Training:\n",
    "        logger.info(f\"Filtering twitter data to data before '{predict_date_str}'.\")\n",
    "        df_twitter_raw = df_twitter_raw[df_twitter_raw[\"date\"] < predict_date_str]\n",
    "    else:\n",
    "        logger.info(f\"Filtering twitter data to only '{predict_date_str}'.\")\n",
    "        df_twitter_raw = df_twitter_raw[df_twitter_raw[\"date\"] == predict_date_str]\n",
    "        model_xgb = twitter_ml_utils.load_model_for_prediction()\n",
    "        cat_uniques = model_xgb.cat_uniques\n",
    "\n",
    "    if df_twitter_raw.shape[0] == 0:\n",
    "        logger.info(f\"No twitter data on {predict_date_str}\")\n",
    "        return False\n",
    "\n",
    "    logger.info(f\"Max date: {df_twitter_raw['date'].max()}\")\n",
    "    logger.info(f\"Num tweet records: {df_twitter_raw.shape[0]:,}\")\n",
    "\n",
    "    # twitter_ml_utils.show_distribution(df=df_twitter_raw)\n",
    "\n",
    "    logger.info(\"Converting twitter data - phase I ...\")\n",
    "    df_booled = twitter_service.convert_to_bool(df=df_twitter_raw)\n",
    "    df_twitter = twitter_ml_utils.convert_twitter_to_numeric(df=df_booled)\n",
    "\n",
    "    logger.info(\"Getting Twitter stock data ...\")\n",
    "    df_stock_data = twitter_ml_utils.get_twitter_stock_data(df_tweets=df_twitter,\n",
    "                                                            num_hold_days=num_hold_days,\n",
    "                                                            workflow_mode=workflow_mode)\n",
    "\n",
    "    logger.info(f\"Num Twitter stock data records: {df_stock_data.shape[0]}\")\n",
    "\n",
    "    logger.info(\"Getting Twitter stock quarterly data ...\")\n",
    "    df_rec_quart_drop = twitter_service.get_all_quarterly_data_for_twitter()\n",
    "\n",
    "    columns_fundy = list(df_rec_quart_drop.columns)\n",
    "\n",
    "    df_result = twitter_ml_utils.merge_fundies_with_stock(df_stock_data=df_stock_data)\n",
    "    df_drop_init = df_result.dropna(subset=[\"date\"]).drop(columns=\"lastupdated_eq_fun\")\n",
    "    df_drop_future = df_drop_init[df_drop_init[\"date\"] > df_drop_init[\"calendardate\"]]\n",
    "    df_drop_future = df_drop_future.sort_values(by=[\"ticker\", \"date\", \"calendardate\"], ascending=False)\n",
    "    df_stock_and_quarter = df_drop_future.drop_duplicates(subset=[\"ticker\", \"date\"], keep=\"first\")\n",
    "    logger.info(\"Finished merging in quarterly stock data.\")\n",
    "\n",
    "    logger.info(\"Getting Nasdaq categorized ticker columns ...\")\n",
    "    df_nas_tickers_info, cat_uniques = ticker_service.get_nasdaq_tickers(cat_uniques=cat_uniques)\n",
    "\n",
    "    logger.info(f\"Num rows from NASDAQ categorized tickers: {df_nas_tickers_info.shape[0]}\")\n",
    "    col_ticker = \"ticker_drop\"\n",
    "\n",
    "    df_stock_quart_info = pd.merge(df_stock_and_quarter, df_nas_tickers_info, how='inner', left_on=[\"ticker\"], right_on=[col_ticker])\n",
    "    df_sqi = df_stock_quart_info.drop(columns=[col_ticker])\n",
    "\n",
    "    df_stock_renamed = df_sqi.rename(columns={\"ticker\": \"f22_ticker\"})\n",
    "\n",
    "    if 'None' in df_stock_renamed.columns:\n",
    "        df_stock_renamed = df_stock_renamed.drop(columns=['None'])\n",
    "\n",
    "    logger.info(\"Merging Tweets with stock data ...\")\n",
    "    df_merged = pd.merge(df_twitter, df_stock_renamed, how='inner', left_on=[\"f22_ticker\", \"date\"], right_on=[\"f22_ticker\", \"date\"])\n",
    "\n",
    "    logger.info(f\"Num rows from merged {df_merged.shape[0]}\")\n",
    "\n",
    "    if df_merged.shape[0] == 0:\n",
    "        logger.info(\"Not enough data after merge.\")\n",
    "        return False\n",
    "\n",
    "    df_days = twitter_ml_utils.add_days_since_quarter_results(df=df_merged)\n",
    "\n",
    "    logger.info(\"Adding meta information about dates (day of week, day of month, etc).\")\n",
    "    df_days_of = twitter_ml_utils.add_calendar_days(df=df_days)\n",
    "\n",
    "    logger.info(\"Adding nasdaq roi rates.\")\n",
    "    df_dd = twitter_ml_utils.add_nasdaq_roi_new(df=df_days_of, num_hold_days=num_hold_days)\n",
    "\n",
    "    if workflow_mode == WorkflowMode.Training:\n",
    "        logger.info(\"Adding buy/sell label for training ...\")\n",
    "        df_thin_rabbit = twitter_service.add_buy_sell(df=df_dd)\n",
    "    else:\n",
    "        df_thin_rabbit = df_dd\n",
    "\n",
    "    df_thin_rabbit[\"original_close_price\"] = df_thin_rabbit[\"close\"]\n",
    "    df_thin_rabbit[\"date\"].max()\n",
    "    logger.info(f'Num df_thin_rabbit: {df_thin_rabbit.shape[0]}')\n",
    "\n",
    "    # NOTE: 2021-01-03: chris.flesche: For NLP\n",
    "    # save_twitter_stock_join(df=df_thin_rabbit)\n",
    "\n",
    "    cols_fundy_numeric = list(set(columns_fundy) - {\"ticker\", 'calendardate', 'datekey', 'reportperiod'})\n",
    "\n",
    "    df_no_z = twitter_service.fill_null_numeric(df=df_thin_rabbit, cols_fundy_numeric=cols_fundy_numeric)\n",
    "\n",
    "    logger.info(\"Adding simple moving average data ...\")\n",
    "    df_since_sma = twitter_ml_utils.add_sma_stuff(df=df_no_z)\n",
    "\n",
    "    df_since_sma[\"purchase_date\"] = df_since_sma[\"date\"]\n",
    "\n",
    "    logger.info(\"Adding days until sale ...\")\n",
    "    df_days_until = ticker_service.add_days_until_sale(df=df_since_sma)\n",
    "\n",
    "    df = twitter_service.refine_pool(df=df_days_until, min_volume=None, min_price=None, max_price=None)\n",
    "    df = twitter_service.omit_columns(df=df)\n",
    "    df_tweet_counted = twitter_service.add_tweet_count(df=df).drop(columns=[\"calendardate\", \"reportperiod\", \"dimension\", \"datekey\"])\n",
    "\n",
    "    # NOTE: 2021-01-03: chris.flesche:\n",
    "    # df_winnowed = twitter_ml_utils.truncate_avail_columns(df=df_tweet_counted)\n",
    "\n",
    "    df_ranked = twitter_ml_utils.add_tip_ranks(df=df_tweet_counted, tr_file_path=constants.TIP_RANKED_DATA_PATH)\n",
    "\n",
    "    df_ticker_hotted, unique_tickers = ticker_service.make_f22_ticker_one_hotted(df_ranked=df_ranked, cat_uniques=cat_uniques)\n",
    "    cat_uniques[\"f22_ticker\"] = unique_tickers\n",
    "\n",
    "    narrow_cols = list(df_ticker_hotted.columns)\n",
    "\n",
    "    print(f\"Number of train_hotted {df_ticker_hotted.shape[0]}.\")\n",
    "\n",
    "    df_train = df_ticker_hotted\n",
    "\n",
    "    logger.info(f\"Num rows of prepared data: {df_train.shape[0]}\")\n",
    "    logger.info(f\"Oldest date of prepared data (future_date): {df_train['future_date'].max()}\")\n",
    "    logger.info(f\"Num unique tickers: {len(cat_uniques['f22_ticker'])}\")\n",
    "\n",
    "    overall_roi = []\n",
    "    if workflow_mode is WorkflowMode.Training:\n",
    "        # sac_roi_list = twitter_ml_utils.find_ml_pred_perf(df=df_train)\n",
    "        # sac_roi_list = twitter_ml_utils.torch_non_linear(df=df_train, narrow_cols=narrow_cols)\n",
    "        logger.info(\"Starting XGB training ...\")\n",
    "        sac_roi_list, did_train = twitter_ml_utils.xgb_learning(df=df_train, narrow_cols=narrow_cols, cat_uniques=cat_uniques)\n",
    "\n",
    "        if not did_train:\n",
    "            return False\n",
    "\n",
    "        investment = 1000\n",
    "        for s in sac_roi_list:\n",
    "            investment = (investment * s) + investment\n",
    "\n",
    "        logger.info(f\"roi amount: {investment}\")\n",
    "        logger.info(sac_roi_list)\n",
    "        if len(sac_roi_list) > 0:\n",
    "            overall_roi.append(mean(sac_roi_list))\n",
    "\n",
    "    if len(overall_roi) > 0:\n",
    "        print(f\"Overall roi: {mean(overall_roi)}\")\n",
    "\n",
    "    overwrite_file = False\n",
    "\n",
    "    if workflow_mode is WorkflowMode.Prediction:\n",
    "        logger.info(\"Converting Pandas dataframe to numpy array for prediction step ...\")\n",
    "\n",
    "        def get_data_for_predictions(df: pd.DataFrame, narrow_cols: List[str]):\n",
    "            feature_cols = twitter_service.get_feature_columns(narrow_cols)\n",
    "\n",
    "            return np.array(df[feature_cols])\n",
    "\n",
    "        X_predict = get_data_for_predictions(df=df_ticker_hotted, narrow_cols=narrow_cols)\n",
    "\n",
    "        logger.info(\"Invoking model prediction ...\")\n",
    "        prediction = model_xgb.model.predict(X_predict)\n",
    "\n",
    "        df_ticker_hotted[\"prediction\"] = prediction\n",
    "\n",
    "        df_buy = df_ticker_hotted[df_ticker_hotted[\"prediction\"] == 1][[\"f22_ticker\", \"purchase_date\", \"future_date\", \"original_close_price\", \"future_close\"]]\n",
    "\n",
    "        df_buy[\"num_hold_days\"] = num_hold_days\n",
    "        df_buy[\"run_timestamp\"] = datetime.timestamp(datetime.now())\n",
    "\n",
    "        df_preds = pd.read_csv(constants.TWITTER_PREDICTIONS_PATH)\n",
    "        df_preds = df_preds[~((df_preds[\"purchase_date\"] == predict_date_str) & (df_preds[\"num_hold_days\"] == num_hold_days))]\n",
    "\n",
    "        logger.info(f\"Old rows found: {df_preds.shape[0]}\")\n",
    "\n",
    "        if overwrite_file:\n",
    "            df_combined = df_buy\n",
    "        else:\n",
    "            df_combined = pd.concat([df_preds, df_buy], axis=0)\n",
    "\n",
    "        logger.info(\"Writing predictions to output ...\")\n",
    "        df_combined.to_csv(constants.TWITTER_PREDICTIONS_PATH, index=False)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def pred_and_train(predict_date_str: str, num_hold_days: int, df_tweets: pd.DataFrame):\n",
    "    had_enough_data = process(df_twitter_raw=df_tweets,\n",
    "                              predict_date_str=predict_date_str,\n",
    "                              workflow_mode=WorkflowMode.Training,\n",
    "                              num_hold_days=num_hold_days)\n",
    "\n",
    "    if had_enough_data:\n",
    "        process(df_twitter_raw=df_tweets,\n",
    "                predict_date_str=predict_date_str,\n",
    "                workflow_mode=WorkflowMode.Prediction,\n",
    "                num_hold_days=num_hold_days)\n",
    "\n",
    "\n",
    "def start():\n",
    "    # today_dt_str = date_utils.get_standard_ymd_format(datetime.now())\n",
    "    learning_prep_dir = Path(constants.TWITTER_GREAT_REDUCTION_DIR, \"main\")\n",
    "    df_tweets = twitter_ml_utils.load_twitter_raw(learning_prep_dir=learning_prep_dir)\n",
    "\n",
    "    # df_tweets = df_tweets.sample(frac=.4)\n",
    "\n",
    "    start_date_str = \"2020-08-10\"\n",
    "    start_dt = date_utils.parse_std_datestring(start_date_str)\n",
    "    num_days_train = 15\n",
    "    num_hold_days = 5\n",
    "\n",
    "    for day_ndx in range(num_days_train - 1, -1, -1):\n",
    "        dt = start_dt + timedelta(days=day_ndx)\n",
    "        predict_date_str = date_utils.get_standard_ymd_format(dt)\n",
    "\n",
    "        if df_tweets[df_tweets[\"date\"] > predict_date_str].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        pred_and_train(df_tweets=df_tweets, predict_date_str=predict_date_str, num_hold_days=num_hold_days)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}