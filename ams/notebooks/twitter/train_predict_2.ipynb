{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "paths_to_add = ['/home/jovyan/work', '/home/jupyter/alpha_media_signal']\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "        \n",
    "from datetime import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ams.config import constants, logger_factory\n",
    "from ams.services import twitter_service\n",
    "from ams.services import ticker_service\n",
    "from ams.notebooks.twitter.twitter_ml_utils import  get_data_for_predictions\n",
    "from ams.notebooks.twitter import twitter_ml_utils\n",
    "from ams.utils import date_utils\n",
    "import xgboost as xgb\n",
    "from ams.machine_learning.twitter import pred_perf_testing\n",
    "from datetime import timedelta\n",
    "from typing import Dict\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "logger = logger_factory.create(__name__)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_good_date(dt):\n",
    "    result = True\n",
    "    if date_utils.is_stock_market_closed(dt):\n",
    "        logger.info(\"No can do. Market closed.\")\n",
    "        result = False\n",
    "    return result\n",
    "\n",
    "def get_stock_matchable(df):\n",
    "    tickers = list(set(df[\"f22_ticker\"].to_list()))\n",
    "    \n",
    "    good_tickers = []\n",
    "    for t in tickers:\n",
    "        if ticker_service.does_ticker_data_exist(ticker=t):\n",
    "            good_tickers.append(t)\n",
    "    \n",
    "    return df[df[\"f22_ticker\"].isin(good_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "overall_roi = []\n",
    "cat_uniques = None\n",
    "overall_roi = None\n",
    "# start_date = date_utils.get_standard_ymd_format(datetime.now())\n",
    "learning_prep_dir = Path(constants.TWITTER_GREAT_REDUCTION_DIR, \"main\")\n",
    "df_tweets = twitter_ml_utils.load_twitter_raw(learning_prep_dir=learning_prep_dir)\n",
    "df_tweets_joinable = get_stock_matchable(df=df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# twitter_ml_utils.show_distribution(df=df_tweets_joinable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def convert_columns(df):\n",
    "    df_booled = twitter_service.convert_to_bool(df=df)\n",
    "    return twitter_ml_utils.convert_twitter_to_numeric(df=df_booled)\n",
    "\n",
    "# df_twitter = convert_columns(df=df_tweets_joinable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_stocks_based_on_tweets(df, prediction_date_str, num_hold_days):\n",
    "    df_stock_tweets = df[df[\"date\"] < predict_date_str]\n",
    "    df_stock_data = twitter_ml_utils.get_twitter_stock_data_2(df_tweets=df_stock_tweets,\n",
    "                                                            num_hold_days=num_hold_days)\n",
    "\n",
    "    prediction_tickers = list(df[df[\"date\"] == predict_date_str][\"f22_ticker\"].unique())\n",
    "\n",
    "    future_date = twitter_ml_utils.get_next_market_date(predict_date_str, num_hold_days)\n",
    "\n",
    "    rows = []\n",
    "    attributes = (\"volume\", \"close\")\n",
    "    for t in prediction_tickers:\n",
    "        prev_volume, prev_close = ticker_service.get_most_recent_stock_values(ticker=t, attributes=attributes)\n",
    "        rows.append({\"ticker\": t, \"date\": predict_date_str, \"future_date\": future_date,\n",
    "                     \"prev_volume\": prev_volume, \"prev_close\": prev_close\n",
    "                    })\n",
    "\n",
    "    df_stock_predict_data = pd.DataFrame(rows)\n",
    "\n",
    "    return pd.concat([df_stock_data, df_stock_predict_data], axis=0)\n",
    "\n",
    "# df_sd_futured = get_stocks_based_on_tweets(df=df_twitter, prediction_date_str=predict_date_str, num_hold_days=num_hold_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_quarterly_data():\n",
    "    global df_rec_quart_drop\n",
    "    if df_rec_quart_drop is None:\n",
    "        df_rec_quart_drop = twitter_service.get_all_quarterly_data_for_twitter()\n",
    "    return df_rec_quart_drop.copy()\n",
    "\n",
    "def combine_with_quarterly_stock_data(df):\n",
    "    df_rec_quart_drop = get_quarterly_data()\n",
    "    columns_fundy = list(df_rec_quart_drop.columns)\n",
    "    df_result = twitter_ml_utils.merge_fundies_with_stock(df_stock_data=df)\n",
    "    df_drop_init = df_result.dropna(subset=[\"date\"]).copy().drop(columns=\"lastupdated_eq_fun\").copy()\n",
    "    df_drop_future = df_drop_init[df_drop_init[\"date\"] > df_drop_init[\"calendardate\"]].copy()\n",
    "    df_drop_future = df_drop_future.sort_values(by=[\"ticker\", \"date\", \"calendardate\"], ascending=False).copy()\n",
    "    df_stock_and_quarter = df_drop_future.drop_duplicates(subset=[\"ticker\", \"date\"], keep=\"first\").copy()\n",
    "    logger.info(\"Finished merging in quarterly stock data.\")\n",
    "    \n",
    "    return df_stock_and_quarter, columns_fundy\n",
    "\n",
    "# df_stock_and_quarter, columns_fundy = combine_with_quarterly_stock_data(df=df_sd_futured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def merge_tweets_with_stock_data(df_twitter, df_stock_and_quarter, cat_uniques):\n",
    "    df_nas_tickers_info, cat_uniques = ticker_service.get_nasdaq_tickers(cat_uniques=cat_uniques)\n",
    "\n",
    "    col_ticker = \"ticker_drop\"\n",
    "\n",
    "    df_stock_quart_info = pd.merge(df_stock_and_quarter, df_nas_tickers_info, how='inner', left_on=[\"ticker\"], right_on=[col_ticker])\n",
    "    df_sqi = df_stock_quart_info.drop(columns=[col_ticker])\n",
    "\n",
    "    df_stock_renamed = df_sqi.rename(columns={\"ticker\": \"f22_ticker\"})\n",
    "\n",
    "    if 'None' in df_stock_renamed.columns:\n",
    "        df_stock_renamed = df_stock_renamed.drop(columns=['None'])\n",
    "\n",
    "    df_merged = pd.merge(df_twitter, df_stock_renamed, how='inner', left_on=[\"f22_ticker\", \"date\"], right_on=[\"f22_ticker\", \"date\"])\n",
    "\n",
    "    if df_merged.shape[0] == 0:\n",
    "        logger.info(\"Not enough data after merge.\")\n",
    "        \n",
    "    df_ranked = twitter_ml_utils.add_tip_ranks(df=df_merged, tr_file_path=constants.TIP_RANKED_DATA_PATH)\n",
    "    \n",
    "    return df_ranked, cat_uniques\n",
    "\n",
    "# df_merged, cat_uniques = merge_tweets_with_stock_data(df_twitter=df_twitter, df_stock_and_quarter=df_stock_and_quarter, cat_uniques=cat_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def supplement_predict(df, predict_date_str: str):\n",
    "    df_train = df[df[\"date\"] != predict_date_str].copy()\n",
    "    df_predict = df[df[\"date\"] == predict_date_str].copy()\n",
    "        \n",
    "    df_predict = ticker_service.get_equity_on_prev_trading_day(df=df_predict, date_str=predict_date_str)\n",
    "    df_predict.loc[:, \"open\"] = df_predict[\"prev_open\"]\n",
    "    df_predict.loc[:, \"low\"] = df_predict[\"prev_low\"]\n",
    "    df_predict.loc[:, \"high\"] = df_predict[\"prev_high\"]\n",
    "    df_predict.loc[:, \"close\"] = df_predict[\"prev_close\"]\n",
    "    df_predict.loc[:, \"original_close_price\"] = df_predict[\"prev_close\"]\n",
    "    \n",
    "    df_combined = pd.concat([df_train, df_predict], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "# df_supple = supplement_predict(df=df_merged, predict_date_str=predict_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def add_calendar_info(df, predict_date_str, columns_fundy):\n",
    "    cols_fundy_numeric = list(set(columns_fundy) - {\"ticker\", 'calendardate', 'datekey', 'reportperiod'})\n",
    "\n",
    "    df_days = twitter_ml_utils.add_days_since_quarter_results(df=df)\n",
    "\n",
    "    df_days_of = twitter_ml_utils.add_calendar_days(df=df_days)\n",
    "\n",
    "    df_dd = twitter_ml_utils.add_nasdaq_roi_new(df=df_days_of, num_hold_days=num_hold_days)\n",
    "\n",
    "    # FIXME: 2021-01-15: chris.flesche: \"close\" should be approximated for when predicting (?)\n",
    "    df_dd.loc[:, \"original_close_price\"] = df_dd[\"close\"]\n",
    "\n",
    "    # # NOTE: 2021-01-03: chris.flesche: For NLP\n",
    "    # # save_twitter_stock_join(df=df_thin_rabbit)\n",
    "\n",
    "    df_no_z = twitter_service.fill_null_numeric(df=df_dd, cols_fundy_numeric=cols_fundy_numeric)\n",
    "    \n",
    "    df_since_sma = twitter_ml_utils.add_sma_stuff(df=df_no_z, predict_date_str=predict_date_str)\n",
    "    \n",
    "    df_since_sma.loc[:, \"purchase_date\"] = df_since_sma[\"date\"]\n",
    "\n",
    "    df_days_until = ticker_service.add_days_until_sale(df=df_since_sma)\n",
    "    \n",
    "    return df_days_until\n",
    "\n",
    "# df_days_until = add_calendar_info(df=df_supple, predict_date_str=predict_date_str, columns_fundy=columns_fundy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def refine_and_drop_cols(df):\n",
    "    df = twitter_service.refine_pool(df=df, min_volume=None, min_price=None, max_price=None)\n",
    "    df = twitter_service.omit_columns(df=df)\n",
    "    return df.drop(columns=[\"calendardate\", \"reportperiod\", \"dimension\", \"datekey\"])\n",
    "\n",
    "# df_refined = refine_and_drop_cols(df_days_until)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: 2021-01-03: chris.flesche:\n",
    "# df_winnowed = twitter_ml_utils.truncate_avail_columns(df=df_tweet_counted)\n",
    "def one_hot(df, cat_uniques):\n",
    "    df_ticker_hotted, unique_tickers = ticker_service.make_f22_ticker_one_hotted(df_ranked=df, cat_uniques=cat_uniques)\n",
    "    cat_uniques[\"f22_ticker\"] = unique_tickers\n",
    "\n",
    "    narrow_cols = list(df_ticker_hotted.columns)\n",
    "\n",
    "    print(f\"Number of train_hotted {df_ticker_hotted.shape[0]}.\")\n",
    "    \n",
    "    return df_ticker_hotted, narrow_cols, cat_uniques\n",
    "\n",
    "# df_ticker_hotted, narrow_cols, cat_uniques = one_hot(df=df_refined, cat_uniques=cat_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train_predict(df_train, df_predict, narrow_cols):\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in true_divide\")\n",
    "        X_train, y_train, standard_scaler = twitter_ml_utils.transform_to_numpy(df=df_train, narrow_cols=narrow_cols)\n",
    "\n",
    "        model = xgb.XGBClassifier(max_depth=4)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    X_predict = get_data_for_predictions(df=df_predict, narrow_cols=narrow_cols, standard_scaler=standard_scaler)\n",
    "\n",
    "    logger.info(\"Invoking model prediction ...\")\n",
    "    prediction = model.predict(X_predict)\n",
    "\n",
    "    df_predict.loc[:, \"prediction\"] = prediction\n",
    "    \n",
    "    return df_predict\n",
    "\n",
    "# df_predict = train_predict(df_train=df_train, df_predict=df_predict)\n",
    "# df_null = df_train.isnull().sum().to_frame('nulls')\n",
    "# df_null[df_null[\"nulls\"] > 0].head(5000)\n",
    "\n",
    "# for nc in narrow_cols:\n",
    "#     if not nc.startswith(\"industry_\") \\\n",
    "#     and not nc.startswith(\"famaindustry_\") \\\n",
    "#     and not nc.startswith(\"industry_\") \\\n",
    "#     and not nc.startswith(\"sector_\") \\\n",
    "#     and not nc.startswith(\"sicsector_\") \\\n",
    "#     and not nc.startswith(\"currency_\") \\\n",
    "#     and not nc.startswith(\"f22_ticker_\") \\\n",
    "#     and not nc.startswith(\"scalerevenue_\") \\\n",
    "#     and not nc.startswith(\"scalemarketcap_\") \\\n",
    "#     and not nc.startswith(\"location_\") \\\n",
    "#     and \"date\" in nc:\n",
    "#         print(nc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def persist_predictions(df_buy, predict_date_str: str, num_hold_days: int):\n",
    "    overwrite_file = False\n",
    "    df_preds = pd.read_csv(constants.TWITTER_PREDICTIONS_PATH)\n",
    "    df_preds = df_preds[~((df_preds[\"purchase_date\"] == predict_date_str) & (df_preds[\"num_hold_days\"] == num_hold_days))]\n",
    "\n",
    "    logger.info(f\"Old rows found: {df_preds.shape[0]}\")\n",
    "\n",
    "    if overwrite_file:\n",
    "        df_combined = df_buy\n",
    "    else:\n",
    "        df_combined = pd.concat([df_preds, df_buy], axis=0)\n",
    "\n",
    "    logger.info(\"Writing predictions to output ...\")\n",
    "    df_combined.to_csv(constants.TWITTER_PREDICTIONS_PATH, index=False)\n",
    "\n",
    "def show_prediction_results(df_predict, predict_date_str, num_hold_days):\n",
    "    df_buy = df_predict[df_predict[\"prediction\"] == 1][[\"f22_ticker\", \"purchase_date\", \"future_date\"]]\n",
    "    df_buy[\"num_hold_days\"] = num_hold_days\n",
    "    df_buy[\"run_timestamp\"] = datetime.timestamp(datetime.now())\n",
    "    \n",
    "    persist_predictions(df_buy=df_buy, predict_date_str=predict_date_str, num_hold_days=num_hold_days)\n",
    "\n",
    "    days_roi_1 = pred_perf_testing.get_days_roi_from_prediction_table(df_preds=df_buy, date_str=predict_date_str, num_hold_days=1)\n",
    "\n",
    "    days_roi_5 = pred_perf_testing.get_days_roi_from_prediction_table(df_preds=df_buy, date_str=predict_date_str, num_hold_days=5)\n",
    "\n",
    "    return days_roi_1, days_roi_5\n",
    " \n",
    "# roi_1_day, roi_5_days = show_prediction_results(df_predict, predict_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_day(df, predict_date_str: str, cat_uniques: Dict, num_hold_days: int):\n",
    "    df_twitter = convert_columns(df=df)\n",
    "    \n",
    "    df_sd_futured = get_stocks_based_on_tweets(df=df_twitter, prediction_date_str=predict_date_str, num_hold_days=num_hold_days)\n",
    "    df_stock_and_quarter, columns_fundy = combine_with_quarterly_stock_data(df=df_sd_futured)\n",
    "    df_merged, cat_uniques = merge_tweets_with_stock_data(df_twitter=df_twitter, df_stock_and_quarter=df_stock_and_quarter, cat_uniques=cat_uniques)\n",
    "    \n",
    "    df_days_until = add_calendar_info(df=df_merged, predict_date_str=predict_date_str, columns_fundy=columns_fundy)\n",
    "    \n",
    "    df_refined = refine_and_drop_cols(df_days_until)\n",
    "        \n",
    "    df_ticker_hotted, narrow_cols, cat_uniques = one_hot(df=df_refined, cat_uniques=cat_uniques)\n",
    "    \n",
    "    if df_ticker_hotted is None or df_ticker_hotted.shape[0] == 0:\n",
    "        logger.info(f\"Not enough data on {predict_date_str}\")\n",
    "        return\n",
    "    \n",
    "    df_supple = supplement_predict(df=df_ticker_hotted, predict_date_str=predict_date_str)\n",
    "    \n",
    "    df_train, df_predict = twitter_ml_utils.split_train_predict(df=df_supple, predict_date_str=predict_date_str)\n",
    "    \n",
    "    if df_train is None or df_predict is None or df_predict.shape[0] == 0 or df_train.shape[0] == 0:\n",
    "        logger.info(f\"Not enough data on {predict_date_str}\")\n",
    "        return\n",
    "\n",
    "    df_predict = train_predict(df_train=df_train, df_predict=df_predict, narrow_cols=narrow_cols)\n",
    "    \n",
    "    roi_1_day, roi_5_days = show_prediction_results(df_predict, predict_date_str, num_hold_days)\n",
    "    print(f\"Roi 1: {roi_1_day}: 5: {roi_5_days}\")\n",
    "    \n",
    "    return roi_1_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-19 07:49:39,265 - __main__ - INFO - Finished merging in quarterly stock data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows in play: 32676\n",
      "cat_uniques is not used.\n",
      "Number of train_hotted 16334.\n",
      "16334\n",
      "16334\n",
      "2021-01-19 07:50:57,204 - ams.notebooks.twitter.twitter_ml_utils - INFO - Num rows of prepared data: 16308\n",
      "2021-01-19 07:50:57,208 - ams.notebooks.twitter.twitter_ml_utils - INFO - Oldest date of prepared data (future_date): 2020-08-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16308\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-19 07:51:09,672 - __main__ - INFO - Invoking model prediction ...\n",
      "2021-01-19 07:51:09,793 - __main__ - INFO - Old rows found: 62039\n",
      "2021-01-19 07:51:09,799 - __main__ - INFO - Writing predictions to output ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-27: roi: 0.012654213764949795\n",
      "2020-08-27: roi: -0.05346473370521651\n",
      "Roi 1: 0.012654213764949795: 5: -0.05346473370521651\n",
      "2021-01-19 07:51:49,209 - __main__ - INFO - Finished merging in quarterly stock data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows in play: 32738\n",
      "cat_uniques is not used.\n",
      "Number of train_hotted 16364.\n",
      "16364\n",
      "16364\n",
      "2021-01-19 07:53:07,300 - ams.notebooks.twitter.twitter_ml_utils - INFO - Num rows of prepared data: 16334\n",
      "2021-01-19 07:53:07,305 - ams.notebooks.twitter.twitter_ml_utils - INFO - Oldest date of prepared data (future_date): 2020-08-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16334\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-19 07:53:19,856 - __main__ - INFO - Invoking model prediction ...\n",
      "2021-01-19 07:53:19,985 - __main__ - INFO - Old rows found: 62025\n",
      "2021-01-19 07:53:19,991 - __main__ - INFO - Writing predictions to output ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-28: roi: -0.010981050488607189\n",
      "2020-08-28: roi: -0.006412060441801362\n",
      "Roi 1: -0.010981050488607189: 5: -0.006412060441801362\n",
      "2021-01-19 07:53:20,487 - __main__ - INFO - No can do. Market closed.\n",
      "2021-01-19 07:53:20,488 - __main__ - INFO - No can do. Market closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from statistics import mean\n",
    "\n",
    "# df_tweets_joinable = df_tweets_joinable.sample(frac=.15)\n",
    "\n",
    "start_date = \"2020-08-27\"\n",
    "dt_start = date_utils.parse_std_datestring(start_date)\n",
    "predict_date_str = date_utils.get_standard_ymd_format(dt_start)\n",
    "\n",
    "num_hold_days = 1\n",
    "df_rec_quart_drop = None\n",
    "\n",
    "min_date_str = \"2020-08-10\"\n",
    "max_date_str = \"2021-01-18\"\n",
    "\n",
    "all_roi = []\n",
    "while min_date_str <= predict_date_str <= max_date_str:\n",
    "    while not is_good_date(dt=dt_start):\n",
    "        dt_start = dt_start + timedelta(days=1)\n",
    "        \n",
    "    predict_date_str = date_utils.get_standard_ymd_format(dt_start)\n",
    "    \n",
    "    df_tweets_for_day = df_tweets_joinable[df_tweets_joinable[\"date\"] <= predict_date_str]\n",
    "    \n",
    "    df_predict = df_tweets_joinable[df_tweets_joinable[\"date\"] == predict_date_str]\n",
    "    \n",
    "    if df_predict.shape[0] > 0:\n",
    "        cat_uniques = None\n",
    "        roi_day = predict_day(df=df_tweets_for_day, predict_date_str=predict_date_str, cat_uniques=cat_uniques, num_hold_days=num_hold_days)\n",
    "        all_roi.append(roi_day)\n",
    "    \n",
    "    dt_start = dt_start + timedelta(days=1)\n",
    "\n",
    "print(f\"Overall roi: {mean(all_roi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add overall ROI ongoing.(?)\n",
    "# Add EOD (open, close, high, low) to train and predict. But for predict use previous day. Done\n",
    "# Fix SMA: prev day for open for predict, regular for all other dates\n",
    "# Add num days from start\n",
    "# Add lookup to previous day's prediction roi - seems to follow on-off-on-off pattern.\n",
    "# Change to WorldTradingDaily real time quotes (12hr) to substitute for open, low, high, and estimate close. (or just take current)\n",
    "# WTD not necessary when using historical.\n",
    "# Test yesterday EOD with 4 day estimate.\n",
    "# Test with historical purchase day eod data (open, close, high, low)\n",
    "# Change SMA back to use purchase day-base SMA.\n",
    "# Reprocess all date with by using sums in Great reduction rather than means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}