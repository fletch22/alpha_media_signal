{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "paths_to_add = ['/home/jovyan/work', '/home/jupyter/alpha_media_signal']\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ams.config import constants, logger_factory\n",
    "from ams.services import twitter_service\n",
    "from ams.services import ticker_service\n",
    "\n",
    "from ams.notebooks.twitter.twitter_ml_utils import  get_data_for_predictions\n",
    "from ams.notebooks.twitter import twitter_ml_utils\n",
    "from ams.utils import date_utils\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "logger = logger_factory.create(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_roi = None\n",
    "\n",
    "df_rec_quart_drop = None\n",
    "def get_quarterly_data():\n",
    "    global df_rec_quart_drop\n",
    "    if df_rec_quart_drop is None:\n",
    "        df_rec_quart_drop = twitter_service.get_all_quarterly_data_for_twitter()\n",
    "    return df_rec_quart_drop.copy()\n",
    "\n",
    "overall_roi = []\n",
    "# today_dt_str = date_utils.get_standard_ymd_format(datetime.now())\n",
    "learning_prep_dir = Path(constants.TWITTER_GREAT_REDUCTION_DIR, \"main\")\n",
    "df_tweets = twitter_ml_utils.load_twitter_raw(learning_prep_dir=learning_prep_dir)\n",
    "# df_tweets = df_tweets.sample(frac=.25)\n",
    "\n",
    "start_date = \"2021-01-03\"\n",
    "days_after_start = 3\n",
    "predict_date_str = twitter_ml_utils.get_next_market_date(start_date, days_after_start)\n",
    "num_hold_days = 1\n",
    "\n",
    "cat_uniques = None\n",
    "\n",
    "dt = date_utils.parse_std_datestring(predict_date_str)\n",
    "if date_utils.is_stock_market_closed(dt):\n",
    "    logger.info(\"No can do. Market closed.\")\n",
    "\n",
    "logger.info(f\"Filtering twitter data to on or before '{predict_date_str}'.\")\n",
    "df_tweets = df_tweets[df_tweets[\"date\"] <= predict_date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if df_tweets.shape[0] == 0:\n",
    "    logger.info(f\"No twitter data on {predict_date_str}\")\n",
    "\n",
    "twitter_ml_utils.show_distribution(df=df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def convert_columns(df):\n",
    "    df_booled = twitter_service.convert_to_bool(df=df)\n",
    "    return twitter_ml_utils.convert_twitter_to_numeric(df=df_booled)\n",
    "\n",
    "df_twitter = convert_columns(df=df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_stocks_based_on_tweets(df, prediction_date_str, num_hold_days):\n",
    "    df_stock_tweets = df[df[\"date\"] < predict_date_str]\n",
    "    df_stock_data = twitter_ml_utils.get_twitter_stock_data_2(df_tweets=df_stock_tweets,\n",
    "                                                            num_hold_days=num_hold_days)\n",
    "\n",
    "    prediction_tickers = list(df[df[\"date\"] == predict_date_str][\"f22_ticker\"].unique())\n",
    "\n",
    "    future_date = twitter_ml_utils.get_next_market_date(predict_date_str, num_hold_days)\n",
    "\n",
    "    rows = []\n",
    "    attributes = (\"volume\", \"close\")\n",
    "    for t in prediction_tickers:\n",
    "        prev_volume, prev_close = ticker_service.get_most_recent_stock_values(ticker=t, attributes=attributes)\n",
    "        rows.append({\"ticker\": t, \"date\": predict_date_str, \"future_date\": future_date,\n",
    "                     \"prev_volume\": prev_volume, \"prev_close\": prev_close\n",
    "                    })\n",
    "\n",
    "    df_stock_predict_data = pd.DataFrame(rows)\n",
    "\n",
    "    return pd.concat([df_stock_data, df_stock_predict_data], axis=0)\n",
    "\n",
    "df_sd_futured = get_stocks_based_on_tweets(df=df_twitter, prediction_date_str=prediction_date_str, num_hold_days=num_hold_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def combine_with_quarterly_stock_data(df):\n",
    "    df_rec_quart_drop = get_quarterly_data()\n",
    "    columns_fundy = list(df_rec_quart_drop.columns)\n",
    "    df_result = twitter_ml_utils.merge_fundies_with_stock(df_stock_data=df)\n",
    "    df_drop_init = df_result.dropna(subset=[\"date\"]).drop(columns=\"lastupdated_eq_fun\")\n",
    "    df_drop_future = df_drop_init[df_drop_init[\"date\"] > df_drop_init[\"calendardate\"]]\n",
    "    df_drop_future = df_drop_future.sort_values(by=[\"ticker\", \"date\", \"calendardate\"], ascending=False)\n",
    "    df_stock_and_quarter = df_drop_future.drop_duplicates(subset=[\"ticker\", \"date\"], keep=\"first\")\n",
    "    logger.info(\"Finished merging in quarterly stock data.\")\n",
    "    \n",
    "    return df_stock_and_quarter, columns_fundy\n",
    "\n",
    "df_stock_and_quarter, columns_fundy = combine_with_quarterly_stock_data(df=df_sd_futured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def merge_tweets_with_stock_data(df_twitter, df_stock_and_quarter):\n",
    "    df_nas_tickers_info, cat_uniques = ticker_service.get_nasdaq_tickers(cat_uniques=cat_uniques)\n",
    "\n",
    "    col_ticker = \"ticker_drop\"\n",
    "\n",
    "    df_stock_quart_info = pd.merge(df_stock_and_quarter, df_nas_tickers_info, how='inner', left_on=[\"ticker\"], right_on=[col_ticker])\n",
    "    df_sqi = df_stock_quart_info.drop(columns=[col_ticker])\n",
    "\n",
    "    df_stock_renamed = df_sqi.rename(columns={\"ticker\": \"f22_ticker\"})\n",
    "\n",
    "    if 'None' in df_stock_renamed.columns:\n",
    "        df_stock_renamed = df_stock_renamed.drop(columns=['None'])\n",
    "\n",
    "    df_merged = pd.merge(df_twitter, df_stock_renamed, how='inner', left_on=[\"f22_ticker\", \"date\"], right_on=[\"f22_ticker\", \"date\"])\n",
    "\n",
    "    if df_merged.shape[0] == 0:\n",
    "        logger.info(\"Not enough data after merge.\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "df_merged = merge_tweets_with_stock_data(df_twitter=df_twitter, df_stock_and_quarter=df_stock_and_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_days = twitter_ml_utils.add_days_since_quarter_results(df=df_merged)\n",
    "\n",
    "df_days_of = twitter_ml_utils.add_calendar_days(df=df_days)\n",
    "\n",
    "df_dd = twitter_ml_utils.add_nasdaq_roi_new(df=df_days_of, num_hold_days=num_hold_days)\n",
    "\n",
    "# FIXME: 2021-01-15: chris.flesche: \"close\" should be approximated for when predicting\n",
    "df_dd.loc[:, \"original_close_price\"] = df_dd[\"close\"]\n",
    "df_dd[\"date\"].max()\n",
    "logger.info(f'Num df_dd: {df_dd.shape[0]}')\n",
    "\n",
    "# # NOTE: 2021-01-03: chris.flesche: For NLP\n",
    "# # save_twitter_stock_join(df=df_thin_rabbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols_fundy_numeric = list(set(columns_fundy) - {\"ticker\", 'calendardate', 'datekey', 'reportperiod'})\n",
    "\n",
    "df_no_z = twitter_service.fill_null_numeric(df=df_dd, cols_fundy_numeric=cols_fundy_numeric)\n",
    "\n",
    "df_since_sma = twitter_ml_utils.add_sma_stuff(df=df_no_z)\n",
    "\n",
    "df_since_sma[\"purchase_date\"] = df_since_sma[\"date\"]\n",
    "\n",
    "df_days_until = ticker_service.add_days_until_sale(df=df_since_sma)\n",
    "\n",
    "# FIXME: 2021-01-14: chris.flesche: Use previous day's close for refine pool. Or remove.\n",
    "df = twitter_service.refine_pool(df=df_days_until, min_volume=None, min_price=None, max_price=None)\n",
    "df = twitter_service.omit_columns(df=df)\n",
    "df_tweet_counted = twitter_service.add_tweet_count(df=df).drop(columns=[\"calendardate\", \"reportperiod\", \"dimension\", \"datekey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_tmp = df_tweet_counted[df_tweet_counted[\"date\"] == predict_date_str]\n",
    "df_tmp[[\"f22_ticker\", \"original_close_price\", \"future_date\", \"future_close\", \"pe\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: 2021-01-03: chris.flesche:\n",
    "# df_winnowed = twitter_ml_utils.truncate_avail_columns(df=df_tweet_counted)\n",
    "\n",
    "df_ranked = twitter_ml_utils.add_tip_ranks(df=df_tweet_counted, tr_file_path=constants.TIP_RANKED_DATA_PATH)\n",
    "\n",
    "df_ticker_hotted, unique_tickers = ticker_service.make_f22_ticker_one_hotted(df_ranked=df_ranked, cat_uniques=cat_uniques)\n",
    "cat_uniques[\"f22_ticker\"] = unique_tickers\n",
    "\n",
    "narrow_cols = list(df_ticker_hotted.columns)\n",
    "\n",
    "print(f\"Number of train_hotted {df_ticker_hotted.shape[0]}.\")\n",
    "\n",
    "dates = df_ticker_hotted[\"date\"].to_list()\n",
    "prediction_date_str = predict_date_str #dates[-1]\n",
    "\n",
    "df_th_train = df_ticker_hotted[df_ticker_hotted[\"date\"] < prediction_date_str]\n",
    "df_train = twitter_service.add_buy_sell(df=df_th_train)\n",
    "\n",
    "df_predict = df_ticker_hotted[df_ticker_hotted[\"date\"] == prediction_date_str]\n",
    "\n",
    "logger.info(f\"Num rows of prepared data: {df_train.shape[0]}\")\n",
    "logger.info(f\"Oldest date of prepared data (future_date): {df_train['future_date'].max()}\")\n",
    "logger.info(f\"Num unique tickers: {len(cat_uniques['f22_ticker'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X_train, y_train, standard_scaler = twitter_ml_utils.transform_to_numpy(df=df_train, narrow_cols=narrow_cols)\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# df_predict_tmp = df_predict.copy()\n",
    "# df_predict_tmp.loc[: \"original_close_price\"] == 100.00\n",
    "\n",
    "X_predict = get_data_for_predictions(df=df_predict, narrow_cols=narrow_cols, standard_scaler=standard_scaler)\n",
    "\n",
    "logger.info(\"Invoking model prediction ...\")\n",
    "prediction = model.predict(X_predict)\n",
    "\n",
    "df_predict.loc[:, \"prediction\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_buy = df_predict[df_predict[\"prediction\"] == 1][[\"f22_ticker\", \"purchase_date\", \"future_date\"]]\n",
    "df_buy[\"num_hold_days\"] = num_hold_days\n",
    "df_buy[\"run_timestamp\"] = datetime.timestamp(datetime.now())\n",
    "\n",
    "print(len(df_train.columns))\n",
    "print(df_train.shape[0])\n",
    "print(df_predict.shape[0])\n",
    "print(df_buy.shape[0])\n",
    "df_predict[[\"f22_ticker\", \"prediction\", \"future_date\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ams.machine_learning.twitter import pred_perf_testing\n",
    "\n",
    "nhd = 1  #num_hold_days\n",
    "\n",
    "days_roi_1 = pred_perf_testing.get_days_roi_from_prediction_table(df_preds=df_buy, date_str=prediction_date_str, num_hold_days=1)\n",
    "\n",
    "print(f\"Roi after 1 day: {days_roi_1}\")\n",
    "\n",
    "days_roi_5 = pred_perf_testing.get_days_roi_from_prediction_table(df_preds=df_buy, date_str=prediction_date_str, num_hold_days=5)\n",
    "\n",
    "print(f\"Roi after 5 days: {days_roi_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in df_predict.columns:\n",
    "    if \"roi\" in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}