{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/jovyan/work/ams/notebooks/twitter', '/usr/local/spark/python', '/usr/local/spark/python/lib/py4j-0.10.7-src.zip', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/home/jovyan/.ipython', '/home/jovyan/work']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "paths_to_add = ['/home/jovyan/work']\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up logging...\n",
      "Will use logging path: /home/jovyan/work/data/logs/alpha_media_signal\n"
     ]
    }
   ],
   "source": [
    "from ams.services import spark_service\n",
    "from pyspark.sql import SparkSession, udf\n",
    "from pyspark.sql.functions import udf, struct\n",
    "from ams.services import twitter_service\n",
    "from pyspark.sql import functions as F\n",
    "from pathlib import Path\n",
    "from pyspark.sql.types import StringType, StructType, StructField, BooleanType, MapType, ArrayType, Row\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import re\n",
    "\n",
    "spark = spark_service.get_or_create(app_name='twitter_flatten')\n",
    "\n",
    "sc = spark.sparkContext\n",
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n",
    "LOGGER.info(\"pyspark script logger initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('/home/jovyan/work/data/')\n",
    "\n",
    "twitter_folder = 'twitter'\n",
    "# twitter_folder = 'twitter_test'\n",
    "\n",
    "file_path = Path(data_path, twitter_folder, 'raw_drop', 'stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ams.services import schema_service\n",
    "\n",
    "sample_tweet_path = Path(\"/home/jovyan/work/resources/sample_tweet.json\")\n",
    "tweet_schema = schema_service.get_twitter_schema(spark=spark, twitter_sample_path=sample_tweet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "entity_comma = '&#44;'\n",
    "line_ending_pattern = re.compile(\"[\\r\\n]\")\n",
    "def clean_text(text:str):\n",
    "    result = text\n",
    "    if text is not None and len(text) > 0:\n",
    "        result = re.sub(line_ending_pattern, '', text)\n",
    "        result = re.sub(\",\", entity_comma, result)\n",
    "    return result\n",
    "clean_text_udf = udf(clean_text, StringType())\n",
    "\n",
    "def get_cashtag_info(ticker: str, has_cashtag: bool, ticker_in_text: bool) -> Dict:\n",
    "    return {\"ticker\": ticker, \"has_cashtag\": has_cashtag, \"ticker_in_text\": ticker_in_text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 775817\n"
     ]
    }
   ],
   "source": [
    "df_init = spark.read.json(str(file_path) + \"/*.txt\")\n",
    "\n",
    "# df_init = df_init.limit(100).repartition(25)\n",
    "print(f'Number of rows: {df_init.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of search tuples: 8601\n"
     ]
    }
   ],
   "source": [
    "search_tuples = twitter_service.get_ticker_searchable_tuples()\n",
    "\n",
    "print(f'number of search tuples: {len(search_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773369\n"
     ]
    }
   ],
   "source": [
    "df_unduped = df_init.dropDuplicates(['id'])\n",
    "print(df_unduped.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "# F.col('place.full_name').alias('place_full_name').cast(StringType()),\n",
    "\n",
    "sel_columns = ['created_at',\n",
    "'id',\n",
    "'text',\n",
    "'truncated',\n",
    "'source',\n",
    "'in_reply_to_status_id',\n",
    "'in_reply_to_user_id',\n",
    "'in_reply_to_screen_name',\n",
    "'contributors',\n",
    "'is_quote_status',\n",
    "'retweet_count',\n",
    "'favorite_count',\n",
    "'retweeted',\n",
    "'possibly_sensitive',\n",
    "'lang',\n",
    "F.col('entities.user_mentions')[0].alias('entities_user_mentions_0').cast(StringType()),\n",
    "F.col('entities.user_mentions')[1].alias('entities_user_mentions_1').cast(StringType()),\n",
    "F.col('entities.user_mentions')[2].alias('entities_user_mentions_2').cast(StringType()),\n",
    "F.col('entities.user_mentions')[3].alias('entities_user_mentions_3').cast(StringType()),\n",
    "F.col('entities.urls')[0].alias('entities_urls_0').cast(StringType()),\n",
    "F.col('entities.urls')[1].alias('entities_urls_1').cast(StringType()),\n",
    "F.col('entities.urls')[2].alias('entities_urls_2').cast(StringType()),\n",
    "F.col('entities.urls')[3].alias('entities_urls_3').cast(StringType()),\n",
    "F.col('metadata.iso_language_code').alias('metadata_iso_language_code'),\n",
    "F.col('metadata.result_type').alias('metadata_result_type'),\n",
    "F.col('user.id').alias('user_id'),\n",
    "F.col('user.name').alias('user_name'),\n",
    "F.col('user.screen_name').alias('user_screen_name'),\n",
    "F.col('user.location').alias('user_location'),\n",
    "F.col('user.description').alias('user_description'),\n",
    "F.col('user.url').alias('user_url'),\n",
    "F.col('user.protected').alias('user_protected'),\n",
    "F.col('user.followers_count').alias('user_followers_count').cast(IntegerType()),\n",
    "F.col('user.friends_count').alias('user_friends_count').cast(IntegerType()),\n",
    "F.col('user.listed_count').alias('user_listed_count'),\n",
    "F.col('user.created_at').alias('user_created_at'),\n",
    "F.col('user.favourites_count').alias('user_favourites_count').cast(IntegerType()),\n",
    "F.col('user.utc_offset').alias('user_utc_offset'),\n",
    "F.col('user.time_zone').alias('user_time_zone'),\n",
    "F.col('user.geo_enabled').alias('user_geo_enabled'),\n",
    "F.col('user.verified').alias('user_verified'),\n",
    "F.col('user.statuses_count').alias('user_statuses_count').cast(IntegerType()),\n",
    "F.col('user.lang').alias('user_lang'),\n",
    "F.col('user.contributors_enabled').alias('user_contributors_enabled'),\n",
    "F.col('user.is_translator').alias('user_is_translator'),\n",
    "F.col('user.is_translation_enabled').alias('user_is_translation_enabled'),\n",
    "F.col('user.profile_background_color').alias('user_profile_background_color'),\n",
    "F.col('user.profile_background_image_url').alias('user_profile_background_image_url'),\n",
    "F.col('user.profile_background_image_url_https').alias('user_profile_background_image_url_https'),\n",
    "F.col('user.profile_background_tile').alias('user_profile_background_tile'),\n",
    "F.col('user.profile_image_url').alias('user_profile_image_url'),\n",
    "F.col('user.profile_image_url_https').alias('user_profile_image_url_https'),\n",
    "F.col('user.profile_banner_url').alias('user_profile_banner_url'),\n",
    "F.col('user.profile_link_color').alias('user_profile_link_color'),\n",
    "F.col('user.profile_sidebar_border_color').alias('user_profile_sidebar_border_color'),\n",
    "F.col('user.profile_sidebar_fill_color').alias('user_profile_sidebar_fill_color'),\n",
    "F.col('user.profile_text_color').alias('user_profile_text_color'),\n",
    "F.col('user.profile_use_background_image').alias('user_profile_use_background_image'),\n",
    "F.col('user.has_extended_profile').alias('user_has_extended_profile'),\n",
    "F.col('user.default_profile').alias('user_default_profile'),\n",
    "F.col('user.default_profile_image').alias('user_default_profile_image'),\n",
    "F.col('user.following').alias('user_following'),\n",
    "F.col('user.follow_request_sent').alias('user_follow_request_sent'),\n",
    "F.col('user.notifications').alias('user_notifications'),\n",
    "F.col('user.translator_type').alias('user_translator_type'),\n",
    "F.col('place.country').alias('place_country').cast(StringType()),\n",
    "F.col('place.name').alias('place_name').cast(StringType())\n",
    "]\n",
    "\n",
    "# print(df_init.columns)\n",
    "\n",
    "df_flat = df_unduped.select(*sel_columns)\n",
    "df_thin = df_flat.drop(*['user', 'metadata', 'entities'])\n",
    "\n",
    "# df_thin.select(*['id', 'place_country', 'place_name']).toPandas().head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @boujeebx: *whistle* 🖐🏼😯🤚🏼 ‘fore I go broke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @quiIlcy: There's literally not even one vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @fussybabybitch: Stealthily squirting a fis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @mooniiez: 🌙 CHASE (THE BOYZ) GROUP ORDER: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Marc_crescendo @BriannaPulido2 She is young. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @financial_kf: Waste Management $WMClorox $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @elynam_demigod: 😂😂😂😂#BlazeDem   He say. wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @sam_aroha: #AROHA let's get 1M soon on off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @hancyxo: big flex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United Natural Foods to Release Fiscal 2020 Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Guerito_Zac: What a flex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @Vansbrasil18: Vans x Lil Peep https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @redpillednow123: #154Red Pill Express@redp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>not @ me having a crisis over what the fuck I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>timing timing timing&amp;#44; my xpel's feb calls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @_zotaita_: Um. I really hate to do this bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>amis !! https://t.co/XsqxNb6Wg7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   RT @boujeebx: *whistle* 🖐🏼😯🤚🏼 ‘fore I go broke...\n",
       "1   RT @quiIlcy: There's literally not even one vl...\n",
       "2   RT @fussybabybitch: Stealthily squirting a fis...\n",
       "3   RT @mooniiez: 🌙 CHASE (THE BOYZ) GROUP ORDER: ...\n",
       "4   @Marc_crescendo @BriannaPulido2 She is young. ...\n",
       "5   RT @financial_kf: Waste Management $WMClorox $...\n",
       "6   RT @elynam_demigod: 😂😂😂😂#BlazeDem   He say. wa...\n",
       "7   RT @sam_aroha: #AROHA let's get 1M soon on off...\n",
       "8                               RT @hancyxo: big flex\n",
       "9   United Natural Foods to Release Fiscal 2020 Fo...\n",
       "10                       RT @Guerito_Zac: What a flex\n",
       "11  RT @Vansbrasil18: Vans x Lil Peep https://t.co...\n",
       "12  RT @redpillednow123: #154Red Pill Express@redp...\n",
       "13  not @ me having a crisis over what the fuck I ...\n",
       "14  timing timing timing&#44; my xpel's feb calls ...\n",
       "15  RT @_zotaita_: Um. I really hate to do this bu...\n",
       "16                    amis !! https://t.co/XsqxNb6Wg7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_thin.withColumn(\"text\", clean_text_udf(F.col(\"text\")))\\\n",
    "    .withColumn(\"user_name\", clean_text_udf(F.col(\"user_name\")))\\\n",
    "    .withColumn(\"user_screen_name\", clean_text_udf(F.col(\"user_screen_name\")))\\\n",
    "    .withColumn(\"user_location\", clean_text_udf(F.col(\"user_location\")))\\\n",
    "    .withColumn(\"user_description\", clean_text_udf(F.col(\"user_description\")))\\\n",
    "    .withColumn(\"entities_user_mentions_0\", clean_text_udf(F.col(\"entities_user_mentions_0\")))\\\n",
    "    .withColumn(\"entities_user_mentions_1\", clean_text_udf(F.col(\"entities_user_mentions_1\")))\\\n",
    "    .withColumn(\"entities_user_mentions_2\", clean_text_udf(F.col(\"entities_user_mentions_2\")))\\\n",
    "    .withColumn(\"entities_user_mentions_3\", clean_text_udf(F.col(\"entities_user_mentions_3\")))\\\n",
    "    .withColumn(\"entities_urls_0\", clean_text_udf(F.col(\"entities_urls_0\")))\\\n",
    "    .withColumn(\"entities_urls_1\", clean_text_udf(F.col(\"entities_urls_1\")))\\\n",
    "    .withColumn(\"entities_urls_2\", clean_text_udf(F.col(\"entities_urls_2\")))\\\n",
    "    .withColumn(\"entities_urls_3\", clean_text_udf(F.col(\"entities_urls_3\")))\\\n",
    "    .withColumn(\"place_name\", clean_text_udf(F.col(\"place_name\")))\\\n",
    "    .withColumn(\"place_country\", clean_text_udf(F.col(\"place_country\")))\\\n",
    "    .withColumn(\"user_url\", clean_text_udf(F.col(\"user_url\")))\\\n",
    "    .withColumn(\"user_profile_background_image_url\", clean_text_udf(F.col(\"user_profile_background_image_url\")))\\\n",
    "    .withColumn(\"source\", clean_text_udf(F.col(\"source\")))\\\n",
    "    .withColumn(\"in_reply_to_screen_name\", clean_text_udf(F.col(\"in_reply_to_screen_name\")))\\\n",
    "    .dropDuplicates(['id'])\n",
    "\n",
    "df_clean.select(*['text']).limit(17).toPandas().head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "search_tuples = twitter_service.get_ticker_searchable_tuples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['created_at', 'id', 'text', 'truncated', 'source', 'in_reply_to_status_id', 'in_reply_to_user_id', 'in_reply_to_screen_name', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'retweeted', 'possibly_sensitive', 'lang', 'entities_user_mentions_0', 'entities_user_mentions_1', 'entities_user_mentions_2', 'entities_user_mentions_3', 'entities_urls_0', 'entities_urls_1', 'entities_urls_2', 'entities_urls_3', 'metadata_iso_language_code', 'metadata_result_type', 'user_id', 'user_name', 'user_screen_name', 'user_location', 'user_description', 'user_url', 'user_protected', 'user_followers_count', 'user_friends_count', 'user_listed_count', 'user_created_at', 'user_favourites_count', 'user_utc_offset', 'user_time_zone', 'user_geo_enabled', 'user_verified', 'user_statuses_count', 'user_lang', 'user_contributors_enabled', 'user_is_translator', 'user_is_translation_enabled', 'user_profile_background_color', 'user_profile_background_image_url', 'user_profile_background_image_url_https', 'user_profile_background_tile', 'user_profile_image_url', 'user_profile_image_url_https', 'user_profile_banner_url', 'user_profile_link_color', 'user_profile_sidebar_border_color', 'user_profile_sidebar_fill_color', 'user_profile_text_color', 'user_profile_use_background_image', 'user_has_extended_profile', 'user_default_profile', 'user_default_profile_image', 'user_following', 'user_follow_request_sent', 'user_notifications', 'user_translator_type', 'place_country', 'place_name', 'text_lc', 'source_lc', 'entities_user_mentions_0_lc', 'entities_user_mentions_1_lc', 'entities_user_mentions_2_lc', 'entities_user_mentions_3_lc', 'entities_urls_0_lc', 'entities_urls_1_lc', 'entities_urls_2_lc', 'entities_urls_3_lc', 'user_description_lc', 'user_url_lc']\n"
     ]
    }
   ],
   "source": [
    "columns_to_search = ['text', 'source', 'entities_user_mentions_0', 'entities_user_mentions_1', 'entities_user_mentions_2', 'entities_user_mentions_3', 'entities_urls_0', 'entities_urls_1', 'entities_urls_2', 'entities_urls_3', 'user_description', 'user_url']\n",
    "\n",
    "lc_cols = []\n",
    "for c in columns_to_search:\n",
    "    lc_cols.append(f'{c}_lc')\n",
    "    df_clean = df_clean.withColumn(f'{c}_lc', F.lower(F.col(c)))\n",
    "\n",
    "\n",
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 909703\n",
      "Elapsed: 80.37263621755277 per second.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def get_cashtags_row_wise(row: Row):\n",
    "    cashtags_stock = []\n",
    "    \n",
    "    row_dict = row.asDict()\n",
    "    all_thing = ''\n",
    "    \n",
    "    text = ''\n",
    "    for k in row_dict.keys():\n",
    "        if k.endswith('_lc'):\n",
    "            if k == 'text_lc':\n",
    "                text = row_dict[k]\n",
    "                if text is None:\n",
    "                    text = ''\n",
    "                text_len = len(str(text))\n",
    "            else:\n",
    "                cell = row_dict[k]\n",
    "                cell = '' if cell is None else cell\n",
    "                \n",
    "                if type(cell) != 'str':\n",
    "                    cell = str(cell)\n",
    "                    \n",
    "                if cell is None:\n",
    "                    cell = ''\n",
    "                all_thing += cell \n",
    "    all_thing = text + all_thing\n",
    "            \n",
    "    for s in search_tuples:\n",
    "        ticker = s[0]\n",
    "        ticker_lc = ticker.lower()\n",
    "        name_lc = s[1].lower()\n",
    "        \n",
    "        index = all_thing.find(f'${ticker_lc}')\n",
    "        if index > -1:\n",
    "            ticker_in_text = True if index < text_len else False\n",
    "            cashtags_stock.append(get_cashtag_info(ticker=ticker, has_cashtag=True, ticker_in_text=ticker_in_text))\n",
    "        else:\n",
    "            index_ticker = all_thing.find(ticker_lc)\n",
    "            index_name = all_thing.find(name_lc)\n",
    "            \n",
    "            if index_ticker > -1 and index_name > -1:\n",
    "                ticker_in_text = True if index_ticker < text_len else False\n",
    "                cashtags_stock.append(get_cashtag_info(ticker=ticker, has_cashtag=False, ticker_in_text=ticker_in_text))\n",
    "                \n",
    "        num_other_tickers = len(cashtags_stock) - 1\n",
    "        for tag in cashtags_stock:\n",
    "            tag['num_other_tickers_in_tweet'] = num_other_tickers\n",
    "    \n",
    "    return cashtags_stock\n",
    "          \n",
    "schema = ArrayType(StructType(fields=[StructField('ticker', StringType()),\n",
    "                                      StructField('has_cashtag', BooleanType()),\n",
    "                                      StructField('ticker_in_text', BooleanType()),\n",
    "                                      StructField('num_other_tickers_in_tweet', IntegerType())\n",
    "                                     ]))\n",
    "get_cashtags_row_wise_udf = udf(get_cashtags_row_wise, schema)\n",
    "\n",
    "# df_tmp = df_clean.limit(10)\n",
    "\n",
    "df_f22_flagged = df_clean.withColumn(\"f22\", get_cashtags_row_wise_udf((struct([df_clean[x] for x in df_clean.columns]))))\n",
    "\n",
    "df_f22_exploded = df_f22_flagged.withColumn('f22', explode(F.col('f22')))\n",
    "\n",
    "se_columns = list(set(df_f22_exploded.columns) - set(lc_cols)) + [F.col('f22.ticker').alias('f22_ticker'),\n",
    "                                        F.col('f22.has_cashtag').alias('f22_has_cashtag'),\n",
    "                                        F.col('f22.ticker_in_text').alias('f22_ticker_in_text'),\n",
    "                                        F.col('f22.num_other_tickers_in_tweet').alias('f22_num_other_tickers_in_tweet')\n",
    "                                       ]\n",
    "\n",
    "df_tickered = df_f22_exploded.select(*se_columns).drop('f22')\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "total = df_tickered.count()\n",
    "print(f'Count: {total}')\n",
    "end = time.time()\n",
    "\n",
    "sec_per_record = total / (end - start)\n",
    "\n",
    "print(f'Elapsed: {sec_per_record} per second.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/data/twitter/flattened_drop/tweets_flat_2020-09-20_05-46-31-96.9\n"
     ]
    }
   ],
   "source": [
    "from ams.services import dataframe_services\n",
    "\n",
    "flat_drop_path = Path(data_path, twitter_folder, 'flattened_drop')\n",
    "prefix = \"tweets_flat\"\n",
    "\n",
    "dataframe_services.persist_dataframe_as_csv(df=df_tickered, output_drop_folder_path=flat_drop_path, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = spark.read.csv(str(output_folder_path), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_read.select(*['text']).toPandas().head(17)\n",
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ams.services import file_services\n",
    "\n",
    "csv_list = list(file_services.list_files(output_folder_path, ends_with=\".csv\"))\n",
    "\n",
    "import csv\n",
    "\n",
    "for c in csv_list:\n",
    "    if c.stat().st_size > 0:\n",
    "        df_read = pd.read_csv(str(c), dialect=csv.unix_dialect(), error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "        print(df_read.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
