{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "paths_to_add = ['/home/jovyan/work']\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "print(sys.path)\n",
    "native_spark = True\n",
    "\n",
    "import pandas as pd\n",
    "from ams.services import spark_service\n",
    "\n",
    "import findspark\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, udf\n",
    "from pyspark.sql.functions import udf, struct\n",
    "from ams.services import twitter_service, file_services\n",
    "from pyspark.sql import functions as F\n",
    "from pathlib import Path\n",
    "from pyspark.sql.types import StringType, StructType, StructField, BooleanType, MapType, ArrayType, Row\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import re\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.types import IntegerType\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "spark = spark_service.get_or_create(app_name='twitter_flatten')\n",
    "sc = spark.sparkContext\n",
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n",
    "LOGGER.info(\"pyspark script logger initialized\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ams.config import constants\n",
    "\n",
    "if native_spark:\n",
    "    project_root = \"../../../\"\n",
    "    data_path = Path(constants.DATA_PATH)\n",
    "else:\n",
    "    data_path = Path('/home/jovyan/work/data/')\n",
    "    project_root = \"/home/jovyan/work/\"\n",
    "    \n",
    "twitter_folder = 'twitter'\n",
    "\n",
    "file_path = Path(data_path, twitter_folder, 'fixed_drop', 'main')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ams.services import schema_service\n",
    "\n",
    "sample_tweet_path = Path(project_root, \"resources/sample_tweet.json\")\n",
    "tweet_schema = schema_service.get_twitter_schema(spark=spark, twitter_sample_path=sample_tweet_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "entity_comma = '&#44;'\n",
    "line_ending_pattern = re.compile(\"[\\r\\n]\")\n",
    "def clean_text(text:str):\n",
    "    result = text\n",
    "    if text is not None and len(text) > 0:\n",
    "        result = re.sub(line_ending_pattern, '', text)\n",
    "        result = re.sub(\",\", entity_comma, result)\n",
    "    return result\n",
    "clean_text_udf = udf(clean_text, StringType())\n",
    "\n",
    "def get_cashtag_info(ticker: str, has_cashtag: bool, ticker_in_text: bool) -> Dict:\n",
    "    return {\"ticker\": ticker, \"has_cashtag\": has_cashtag, \"ticker_in_text\": ticker_in_text}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_tuples = twitter_service.get_ticker_searchable_tuples()\n",
    "\n",
    "print(f'number of search tuples: {len(search_tuples)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "def fix_columns(df: DataFrame):\n",
    "    \n",
    "    sel_columns = ['created_at',\n",
    "    'id',\n",
    "    'text',\n",
    "    'truncated',\n",
    "    'source',\n",
    "    'in_reply_to_status_id',\n",
    "    'in_reply_to_user_id',\n",
    "    'in_reply_to_screen_name',\n",
    "    'contributors',\n",
    "    'is_quote_status',\n",
    "    'retweet_count',\n",
    "    'favorite_count',\n",
    "    'retweeted',\n",
    "    'possibly_sensitive',\n",
    "    'lang',\n",
    "    F.col('entities.user_mentions')[0].alias('entities_user_mentions_0').cast(StringType()),\n",
    "    F.col('entities.user_mentions')[1].alias('entities_user_mentions_1').cast(StringType()),\n",
    "    F.col('entities.user_mentions')[2].alias('entities_user_mentions_2').cast(StringType()),\n",
    "    F.col('entities.user_mentions')[3].alias('entities_user_mentions_3').cast(StringType()),\n",
    "    F.col('entities.urls')[0].alias('entities_urls_0').cast(StringType()),\n",
    "    F.col('entities.urls')[1].alias('entities_urls_1').cast(StringType()),\n",
    "    F.col('entities.urls')[2].alias('entities_urls_2').cast(StringType()),\n",
    "    F.col('entities.urls')[3].alias('entities_urls_3').cast(StringType()),\n",
    "    F.col('metadata.iso_language_code').alias('metadata_iso_language_code'),\n",
    "    F.col('metadata.result_type').alias('metadata_result_type'),\n",
    "    F.col('user.id').alias('user_id'),\n",
    "    F.col('user.name').alias('user_name'),\n",
    "    F.col('user.screen_name').alias('user_screen_name'),\n",
    "    F.col('user.location').alias('user_location'),\n",
    "    F.col('user.description').alias('user_description'),\n",
    "    F.col('user.url').alias('user_url'),\n",
    "    F.col('user.protected').alias('user_protected'),\n",
    "    F.col('user.followers_count').alias('user_followers_count').cast(IntegerType()),\n",
    "    F.col('user.friends_count').alias('user_friends_count').cast(IntegerType()),\n",
    "    F.col('user.listed_count').alias('user_listed_count'),\n",
    "    F.col('user.created_at').alias('user_created_at'),\n",
    "    F.col('user.favourites_count').alias('user_favourites_count').cast(IntegerType()),\n",
    "    F.col('user.utc_offset').alias('user_utc_offset'),\n",
    "    F.col('user.time_zone').alias('user_time_zone'),\n",
    "    F.col('user.geo_enabled').alias('user_geo_enabled'),\n",
    "    F.col('user.verified').alias('user_verified'),\n",
    "    F.col('user.statuses_count').alias('user_statuses_count').cast(IntegerType()),\n",
    "    F.col('user.lang').alias('user_lang'),\n",
    "    F.col('user.contributors_enabled').alias('user_contributors_enabled'),\n",
    "    F.col('user.is_translator').alias('user_is_translator'),\n",
    "    F.col('user.is_translation_enabled').alias('user_is_translation_enabled'),\n",
    "    F.col('user.profile_background_color').alias('user_profile_background_color'),\n",
    "    F.col('user.profile_background_image_url').alias('user_profile_background_image_url'),\n",
    "    F.col('user.profile_background_image_url_https').alias('user_profile_background_image_url_https'),\n",
    "    F.col('user.profile_background_tile').alias('user_profile_background_tile'),\n",
    "    F.col('user.profile_image_url').alias('user_profile_image_url'),\n",
    "    F.col('user.profile_image_url_https').alias('user_profile_image_url_https'),\n",
    "    F.col('user.profile_banner_url').alias('user_profile_banner_url'),\n",
    "    F.col('user.profile_link_color').alias('user_profile_link_color'),\n",
    "    F.col('user.profile_sidebar_border_color').alias('user_profile_sidebar_border_color'),\n",
    "    F.col('user.profile_sidebar_fill_color').alias('user_profile_sidebar_fill_color'),\n",
    "    F.col('user.profile_text_color').alias('user_profile_text_color'),\n",
    "    F.col('user.profile_use_background_image').alias('user_profile_use_background_image'),\n",
    "    F.col('user.has_extended_profile').alias('user_has_extended_profile'),\n",
    "    F.col('user.default_profile').alias('user_default_profile'),\n",
    "    F.col('user.default_profile_image').alias('user_default_profile_image'),\n",
    "    F.col('user.following').alias('user_following'),\n",
    "    F.col('user.follow_request_sent').alias('user_follow_request_sent'),\n",
    "    F.col('user.notifications').alias('user_notifications'),\n",
    "    F.col('user.translator_type').alias('user_translator_type'),\n",
    "    F.col('f22_place.place_country').alias('place_country').cast(StringType()),\n",
    "    F.col('f22_place.place_full_name').alias('place_full_name').cast(StringType()),\n",
    "    F.col('f22_place.place_name').alias('place_name').cast(StringType())\n",
    "    ]\n",
    "\n",
    "    df = df.select(*sel_columns)\n",
    "    return df.drop(*['user', 'metadata', 'entities', 'f22_place'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_columns(df: DataFrame):\n",
    "    return df.withColumn(\"text\", clean_text_udf(F.col(\"text\")))\\\n",
    "        .withColumn(\"user_name\", clean_text_udf(F.col(\"user_name\")))\\\n",
    "        .withColumn(\"user_screen_name\", clean_text_udf(F.col(\"user_screen_name\")))\\\n",
    "        .withColumn(\"user_location\", clean_text_udf(F.col(\"user_location\")))\\\n",
    "        .withColumn(\"user_description\", clean_text_udf(F.col(\"user_description\")))\\\n",
    "        .withColumn(\"entities_user_mentions_0\", clean_text_udf(F.col(\"entities_user_mentions_0\")))\\\n",
    "        .withColumn(\"entities_user_mentions_1\", clean_text_udf(F.col(\"entities_user_mentions_1\")))\\\n",
    "        .withColumn(\"entities_user_mentions_2\", clean_text_udf(F.col(\"entities_user_mentions_2\")))\\\n",
    "        .withColumn(\"entities_user_mentions_3\", clean_text_udf(F.col(\"entities_user_mentions_3\")))\\\n",
    "        .withColumn(\"entities_urls_0\", clean_text_udf(F.col(\"entities_urls_0\")))\\\n",
    "        .withColumn(\"entities_urls_1\", clean_text_udf(F.col(\"entities_urls_1\")))\\\n",
    "        .withColumn(\"entities_urls_2\", clean_text_udf(F.col(\"entities_urls_2\")))\\\n",
    "        .withColumn(\"entities_urls_3\", clean_text_udf(F.col(\"entities_urls_3\")))\\\n",
    "        .withColumn(\"place_name\", clean_text_udf(F.col(\"place_name\")))\\\n",
    "        .withColumn(\"user_url\", clean_text_udf(F.col(\"user_url\")))\\\n",
    "        .withColumn(\"user_profile_background_image_url\", clean_text_udf(F.col(\"user_profile_background_image_url\")))\\\n",
    "        .withColumn(\"source\", clean_text_udf(F.col(\"source\")))\\\n",
    "        .withColumn(\"in_reply_to_screen_name\", clean_text_udf(F.col(\"in_reply_to_screen_name\")))\\\n",
    "        .withColumn(\"place_country\", clean_text_udf(F.col(\"place_country\")))\\\n",
    "        .dropDuplicates(['id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_tuples = twitter_service.get_ticker_searchable_tuples()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_cashtags_row_wise(row: Row):\n",
    "    cashtags_stock = []\n",
    "    \n",
    "    row_dict = row.asDict()\n",
    "    all_thing = ''\n",
    "    \n",
    "    text = ''\n",
    "    for k in row_dict.keys():\n",
    "        if k.endswith('_lc'):\n",
    "            if k == 'text_lc':\n",
    "                text = row_dict[k]\n",
    "                if text is None:\n",
    "                    text = ''\n",
    "                text_len = len(str(text))\n",
    "            else:\n",
    "                cell = row_dict[k]\n",
    "                cell = '' if cell is None else cell\n",
    "                \n",
    "                if type(cell) != 'str':\n",
    "                    cell = str(cell)\n",
    "                    \n",
    "                if cell is None:\n",
    "                    cell = ''\n",
    "                all_thing += cell \n",
    "    all_thing = text + all_thing\n",
    "            \n",
    "    for s in search_tuples:\n",
    "        ticker = s[0]\n",
    "        ticker_lc = ticker.lower()\n",
    "        name_lc = s[1].lower()\n",
    "        \n",
    "        index = all_thing.find(f'${ticker_lc}')\n",
    "        if index > -1:\n",
    "            ticker_in_text = True if index < text_len else False\n",
    "            cashtags_stock.append(get_cashtag_info(ticker=ticker, has_cashtag=True, ticker_in_text=ticker_in_text))\n",
    "        else:\n",
    "            index_ticker = all_thing.find(ticker_lc)\n",
    "            index_name = all_thing.find(name_lc)\n",
    "            \n",
    "            if index_ticker > -1 and index_name > -1:\n",
    "                ticker_in_text = True if index_ticker < text_len else False\n",
    "                cashtags_stock.append(get_cashtag_info(ticker=ticker, has_cashtag=False, ticker_in_text=ticker_in_text))\n",
    "                \n",
    "        num_other_tickers = len(cashtags_stock) - 1\n",
    "        for tag in cashtags_stock:\n",
    "            tag['num_other_tickers_in_tweet'] = num_other_tickers\n",
    "    \n",
    "    return cashtags_stock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_tickers_and_explode(df: DataFrame):\n",
    "    \n",
    "    columns_to_search = ['text', 'source', 'entities_user_mentions_0', 'entities_user_mentions_1', 'entities_user_mentions_2', 'entities_user_mentions_3', 'entities_urls_0', 'entities_urls_1', 'entities_urls_2', 'entities_urls_3', 'user_description', 'user_url']\n",
    "    \n",
    "    lc_cols = []\n",
    "    for c in columns_to_search:\n",
    "        lc_cols.append(f'{c}_lc')\n",
    "        df = df.withColumn(f'{c}_lc', F.lower(F.col(c)))\n",
    "\n",
    "          \n",
    "    schema = ArrayType(StructType(fields=[StructField('ticker', StringType()),\n",
    "                                          StructField('has_cashtag', BooleanType()),\n",
    "                                          StructField('ticker_in_text', BooleanType()),\n",
    "                                          StructField('num_other_tickers_in_tweet', IntegerType())\n",
    "                                         ]))\n",
    "    get_cashtags_row_wise_udf = udf(get_cashtags_row_wise, schema)\n",
    "\n",
    "    df = df.withColumn(\"f22\", get_cashtags_row_wise_udf((struct([df[x] for x in df.columns]))))\n",
    "\n",
    "    df = df.withColumn('f22', explode(F.col('f22')))\n",
    "\n",
    "    se_columns = list(set(df.columns) - set(lc_cols)) + [F.col('f22.ticker').alias('f22_ticker'),\n",
    "                                            F.col('f22.has_cashtag').alias('f22_has_cashtag'),\n",
    "                                            F.col('f22.ticker_in_text').alias('f22_ticker_in_text'),\n",
    "                                            F.col('f22.num_other_tickers_in_tweet').alias('f22_num_other_tickers_in_tweet')\n",
    "                                           ]\n",
    "\n",
    "    return df.select(*se_columns).drop('f22')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ams.services import dataframe_services \n",
    "from ams.services.dataframe_services import PersistedDataFrameTypes\n",
    "from retry import retry\n",
    "\n",
    "flat_drop_path = Path(data_path, twitter_folder, 'flattened_drop', \"main\")\n",
    "prefix = \"tweets_flat\"\n",
    "\n",
    "file_type = PersistedDataFrameTypes.PARQUET\n",
    "\n",
    "@retry(tries=3)\n",
    "def persist(df: DataFrame):\n",
    "    dataframe_services.persist_dataframe(df=df, \n",
    "                                         output_drop_folder_path=flat_drop_path, \n",
    "                                         prefix=prefix, \n",
    "                                         num_output_files=20,\n",
    "                                         file_type=file_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_unexpected_null_column(place:str):\n",
    "    result = {\"place_country\": None, \"place_full_name\": None, \"place_name\": None}\n",
    "    if place is not None:\n",
    "        result[\"place_country\"] = place[\"country\"]\n",
    "        result[\"place_full_name\"] = place[\"full_name\"]\n",
    "        result[\"place_name\"] = place[\"name\"]\n",
    "    return result\n",
    "\n",
    "schema = StructType(fields=[StructField('place_country', StringType()),\n",
    "                                          StructField('place_full_name', StringType()),\n",
    "                                          StructField('place_name', StringType()),\n",
    "                                         ])\n",
    "\n",
    "clean_unexpected_null_column_udf = udf(clean_unexpected_null_column, schema)\n",
    "\n",
    "def clean_place(df: DataFrame):\n",
    "    \n",
    "    df = df.withColumn(\"f22_place\", clean_unexpected_null_column_udf(F.col(\"place\")))\n",
    "    df = df.drop(\"place\")\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ams.services import file_services\n",
    "\n",
    "files = file_services.list_files(parent_path=file_path, ends_with=\".txt\")\n",
    "files = [str(f) for f in files]\n",
    "\n",
    "def chunk(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "chunked_list = list(chunk(files, 3))\n",
    "\n",
    "tot_chunks = len(chunked_list)\n",
    "\n",
    "for ndx, chunk in enumerate(chunked_list):\n",
    "#     if ndx + 1 < 22: \n",
    "#         continue\n",
    "        \n",
    "    print(f\"Processing {ndx + 1} of {tot_chunks}.\")\n",
    "    \n",
    "    print(f\"Processing files: {chunk}\")\n",
    "    \n",
    "    df_init = spark.read.json(chunk[0])\n",
    "\n",
    "    df_unduped = df_init.dropDuplicates(['id'])\n",
    "\n",
    "    df_clean_place = clean_place(df=df_unduped)\n",
    "        \n",
    "    df_thin = fix_columns(df=df_clean_place)\n",
    "    \n",
    "    df_clean = clean_columns(df=df_thin)\n",
    "    \n",
    "    df_tickered = find_tickers_and_explode(df=df_clean)\n",
    "        \n",
    "    persist(df=df_tickered)\n",
    "#     persist(df=df_init)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}