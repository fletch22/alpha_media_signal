{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.7\n",
      "IPython 7.17.0\n",
      "\n",
      "numpy 1.19.4\n",
      "pandas 1.1.4\n",
      "torch 1.6.0\n",
      "transformers 3.4.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "%reload_ext watermark\n",
    "\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrew Thomas</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
       "      <td>Update: After getting a response from the deve...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4.17.0.3</td>\n",
       "      <td>2020-04-05 22:25:57</td>\n",
       "      <td>According to our TOS, and the term you have ag...</td>\n",
       "      <td>2020-04-05 15:10:24</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Craig Haines</td>\n",
       "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
       "      <td>Used it for a fair amount of time without any ...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.17.0.3</td>\n",
       "      <td>2020-04-04 13:40:01</td>\n",
       "      <td>It sounds like you logged in with a different ...</td>\n",
       "      <td>2020-04-05 15:11:35</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>steven adkins</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
       "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.17.0.3</td>\n",
       "      <td>2020-04-01 16:18:13</td>\n",
       "      <td>This sounds odd! We are not aware of any issue...</td>\n",
       "      <td>2020-04-02 16:05:56</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lars Panzerbjørn</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
       "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>4.17.0.2</td>\n",
       "      <td>2020-03-12 08:17:34</td>\n",
       "      <td>We do offer this option as part of the Advance...</td>\n",
       "      <td>2020-03-15 06:20:13</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scott Prewitt</td>\n",
       "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
       "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>4.17.0.2</td>\n",
       "      <td>2020-03-14 17:41:01</td>\n",
       "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
       "      <td>2020-03-15 23:45:51</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userName                                          userImage  \\\n",
       "0     Andrew Thomas  https://lh3.googleusercontent.com/a-/AOh14GiHd...   \n",
       "1      Craig Haines  https://lh3.googleusercontent.com/-hoe0kwSJgPQ...   \n",
       "2     steven adkins  https://lh3.googleusercontent.com/a-/AOh14GiXw...   \n",
       "3  Lars Panzerbjørn  https://lh3.googleusercontent.com/a-/AOh14Gg-h...   \n",
       "4     Scott Prewitt  https://lh3.googleusercontent.com/-K-X1-YsVd6U...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Update: After getting a response from the deve...      1             21   \n",
       "1  Used it for a fair amount of time without any ...      1             11   \n",
       "2  Your app sucks now!!!!! Used to be good but no...      1             17   \n",
       "3  It seems OK, but very basic. Recurring tasks n...      1            192   \n",
       "4  Absolutely worthless. This app runs a prohibit...      1             42   \n",
       "\n",
       "  reviewCreatedVersion                   at  \\\n",
       "0             4.17.0.3  2020-04-05 22:25:57   \n",
       "1             4.17.0.3  2020-04-04 13:40:01   \n",
       "2             4.17.0.3  2020-04-01 16:18:13   \n",
       "3             4.17.0.2  2020-03-12 08:17:34   \n",
       "4             4.17.0.2  2020-03-14 17:41:01   \n",
       "\n",
       "                                        replyContent            repliedAt  \\\n",
       "0  According to our TOS, and the term you have ag...  2020-04-05 15:10:24   \n",
       "1  It sounds like you logged in with a different ...  2020-04-05 15:11:35   \n",
       "2  This sounds odd! We are not aware of any issue...  2020-04-02 16:05:56   \n",
       "3  We do offer this option as part of the Advance...  2020-03-15 06:20:13   \n",
       "4  We're sorry you feel this way! 90% of the app ...  2020-03-15 23:45:51   \n",
       "\n",
       "       sortOrder      appId  \n",
       "0  most_relevant  com.anydo  \n",
       "1  most_relevant  com.anydo  \n",
       "2  most_relevant  com.anydo  \n",
       "3  most_relevant  com.anydo  \n",
       "4  most_relevant  com.anydo  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import initialize_notebook\n",
    "from ams.config import constants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "constants.BERT_PATH\n",
    "\n",
    "df = pd.read_csv(constants.BERT_REVIEWS_DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "  rating = int(rating)\n",
    "  if rating <= 2:\n",
    "    return 0\n",
    "  elif rating == 3:\n",
    "    return 1\n",
    "  else: \n",
    "    return 2\n",
    "\n",
    "df['sentiment'] = df.score.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'negative'), Text(0, 0, 'neutral'), Text(0, 0, 'positive')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "ax = sns.countplot(df.sentiment)\n",
    "plt.xlabel('review sentiment')\n",
    "ax.set_xticklabels(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
      "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
      "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Chris\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
       "        1111,  123, 2277,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['attention_mask'][0]))\n",
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'When',\n",
       " 'was',\n",
       " 'I',\n",
       " 'last',\n",
       " 'outside',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'stuck',\n",
       " 'at',\n",
       " 'home',\n",
       " 'for',\n",
       " '2',\n",
       " 'weeks',\n",
       " '.',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df.content:\n",
    "  tokens = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1402: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  ndim = x[:, None].ndim\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\matplotlib\\axes\\_base.py:276: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x = x[:, np.newaxis]\n",
      "C:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\matplotlib\\axes\\_base.py:278: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y = y[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 256]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.content.to_numpy(),\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 160])\n",
      "torch.Size([16, 160])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'], \n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ams.deep_learning.util import get_args, makedirs\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 160])\n",
      "torch.Size([16, 160])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'], \n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ams.deep_learning.util import get_args, makedirs\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.76 GiB already allocated; 2.72 MiB free; 2.98 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-46992c3ae043>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m     20\u001b[0m     outputs = model(\n\u001b[0;32m     21\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m       \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-80d430c6e688>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     12\u001b[0m     _, pooled_output = self.bert(\n\u001b[0;32m     13\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m       \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     )\n\u001b[0;32m     16\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    839\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    480\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m                 )\n\u001b[0;32m    484\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m         )\n\u001b[0;32m    404\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         )\n\u001b[0;32m    341\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.76 GiB already allocated; 2.72 MiB free; 2.98 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'], \n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_hidden_state.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_model.config.hidden_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pooled_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ams.deep_learning.util import get_args, makedirs\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 4.00 GiB total capacity; 2.75 GiB already allocated; 2.72 MiB free; 2.98 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6c9e96402741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 4.00 GiB total capacity; 2.75 GiB already allocated; 2.72 MiB free; 2.98 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from ams.deep_learning.util import get_args, makedirs\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}