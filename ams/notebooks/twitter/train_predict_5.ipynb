{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from ams.twitter.PredictionParamFactory import PredictionParamFactory\n",
    "from ams.twitter.twitter_ml_utils import get_next_market_date\n",
    "from ams.utils import date_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ams.config import constants, logger_factory\n",
    "from ams.services import twitter_service\n",
    "from ams.services import ticker_service\n",
    "from ams.twitter import twitter_ml_utils\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "logger = logger_factory.create(__name__)\n",
    "\n",
    "gc.collect()\n",
    "cell_x = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest tweet: 2021-02-13\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "overall_roi = []\n",
    "df_rec_quart_drop = None\n",
    "\n",
    "great_red_dir = Path(constants.TWITTER_END_DROP)\n",
    "df_tweets = twitter_ml_utils.load_twitter_raw(proc_path=great_red_dir)\n",
    "df_tweets_joinable = twitter_ml_utils.get_stock_matchable(df=df_tweets)\n",
    "\n",
    "print(f\"Oldest tweet: {df_tweets_joinable['date'].max()}\")\n",
    "\n",
    "# pred_params = PredictionParamFactory.create_generic_trainer(df=df, num_hold_days=num_hold_days, max_date_str=max_date_str, min_date_str=min_date_str)\n",
    "\n",
    "tweet_date_str = \"2021-02-10\"\n",
    "\n",
    "tweet_dt = date_utils.parse_std_datestring(tweet_date_str)\n",
    "purchase_date_str = get_next_market_date(date_str=tweet_date_str, num_days=1)\n",
    "num_days_hold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tweet_samp = df_tweets_joinable.sample(frac=.01)\n",
    "\n",
    "if cell_x:\n",
    "    df_tweets = twitter_ml_utils.easy_convert_columns(df=tweet_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_hold_days = 1\n",
    "num_days_until_purchase = 1\n",
    "\n",
    "# print(df_tweets[df_tweets[\"date\"] == \"2021-02-07\"].shape[0])\n",
    "# df_tweets.loc[:, \"purchase_date\"] == df[\"date\"].apply(get_next_market_)\n",
    "\n",
    "if cell_x:\n",
    "    df_sd_futured = twitter_ml_utils.get_stocks_based_on_tweets_2(df_tweets=df_tweets, tweet_date_str=tweet_date_str, num_hold_days=num_hold_days, num_days_until_purchase=num_days_until_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>future_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2020-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>AAME</td>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>2020-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>AAON</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>2020-08-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker        date purchase_date future_date\n",
       "3016    AAL  2020-12-24    2020-12-28  2020-12-29\n",
       "3032    AAL  2021-01-20    2021-01-21  2021-01-22\n",
       "3034   AAME  2021-01-22    2021-01-25  2021-01-26\n",
       "1756   AAOI  2020-09-17    2020-09-18  2020-09-21\n",
       "2928   AAON  2020-08-20    2020-08-21  2020-08-24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if cell_x:\n",
    "    \n",
    "#     print(df_sd_futured.shape[0])\n",
    "#     print(list(df_sd_futured.columns))\n",
    "df_sd_futured[[\"ticker\", \"date\", \"purchase_date\", \"future_date\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-13 19:21:13,419 - ams.twitter.twitter_ml_utils - INFO - Finished merging in quarterly stock data.\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "    df_stock_and_quarter, columns_fundy = twitter_ml_utils.combine_with_quarterly_stock_data(df=df_sd_futured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806\n"
     ]
    }
   ],
   "source": [
    "if cell_x:\n",
    "    print(df_stock_and_quarter.shape[0])\n",
    "#     print(list(df_stock_and_quarter.columns))\n",
    "df_nas_tickers_info = ticker_service.get_nasdaq_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "#     print(df_twitter.shape[0])\n",
    "#     print(df_stock_and_quarter.shape[0])\n",
    "    \n",
    "    df_merged = twitter_ml_utils.merge_tweets_with_stock_data_2(df_twitter=df_tweets, \n",
    "                                         df_stock_and_quarter=df_stock_and_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810\n"
     ]
    }
   ],
   "source": [
    "if cell_x:\n",
    "    print(df_merged.shape[0])\n",
    "    # print(list(df_merged.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "    print(df_merged.shape[0])\n",
    "\n",
    "    df_days_until = twitter_ml_utils.add_calendar_info_2(df=df_merged, \n",
    "                                      columns_fundy=columns_fundy,\n",
    "                                      predict_date_str=predict_date_str,\n",
    "                                      num_hold_days=num_hold_days)\n",
    "\n",
    "    if df_days_until is None:\n",
    "        raise Exception(\"Empty result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if cell_x:\n",
    "    print(df_days_until.shape[0])\n",
    "    df = df_days_until\n",
    "    df_predict = df[df[\"date\"] == s.predict_date_str].copy()\n",
    "\n",
    "    if df_predict is None:\n",
    "        raise Exception(\"Predict dataframe is empty.\")\n",
    "        \n",
    "    # print(list(df_predict.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "    df_refined = twitter_service.refine_pool(df=df, min_volume=None, min_price=None, max_price=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cell_x:\n",
    "    print(df_refined.shape[0])\n",
    "    df_predict = df_refined[df_refined[\"date\"] == s.predict_date_str].copy()\n",
    "    print(f\"df_predict: {df_predict.shape[0]}\")\n",
    "    # print(list(df_predict.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "    df_ticker_hotted, narrow_cols = twitter_ml_utils.one_hot(df=df_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cell_x:\n",
    "    print(f\"df_ticker_hotted: {df_ticker_hotted.shape[0]}\")\n",
    "    df_predict = df_ticker_hotted[df_ticker_hotted[\"date\"] == s.predict_date_str].copy()\n",
    "    print(f\"df_predict: {df_predict.shape[0]}\")\n",
    "    # print(list(df_predict.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "  \n",
    "if cell_x:\n",
    "#     print(list(df_ticker_hotted.columns))\n",
    "    df_prepped = twitter_ml_utils.prep_predict(df=df_ticker_hotted, predict_date_str=s.predict_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "    df_train, df_predict = twitter_ml_utils.split_train_predict(df=df_prepped, predict_date_str=s.predict_date_str)\n",
    "    narrow_cols = twitter_ml_utils.get_train_columns(all_columns=list(df_train.columns))\n",
    "    print(df_train.shape[0])\n",
    "    print(df_predict.shape[0])\n",
    "#     print(narrow_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:  \n",
    "    if df_train is None or df_predict is None or df_predict.shape[0] == 0 or df_train.shape[0] == 0:\n",
    "        logger.info(f\"Not enough data on {s.predict_date_str}\")\n",
    "        raise Exception(\"Error!\")\n",
    "\n",
    "    df_predict = twitter_ml_utils.train_predict(df_train=df_train, df_predict=df_predict, narrow_cols=narrow_cols)\n",
    "    \n",
    "    if df_predict is None:\n",
    "        raise Exception(\"predict dataframe is empty.\")\n",
    "        \n",
    "    print(df_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cell_x:\n",
    "    print(f\"df_train: {df_train.shape[0]}\")\n",
    "    print(f\"df_predict: {df_predict.shape[0]}\")\n",
    "    total_rows = df_predict.shape[0]\n",
    "    buy_rows = df_predict[df_predict[\"prediction\"] == 1].shape[0]\n",
    "    buy_rate = buy_rows/total_rows\n",
    "    print(f\"Purchase rate: {buy_rate:.03f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if cell_x:\n",
    "    num_buys = df_predict[df_predict[\"prediction\"] == 1].shape[0]\n",
    "    roi_1_day, roi_5_days = twitter_ml_utils.show_prediction_results(df_predict, s.predict_date_str, s.num_hold_days)\n",
    "    print(f\"{s.predict_date_str}: num_buys: {num_buys}; Roi 1: {roi_1_day}: 5: {roi_5_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if cell_x:\n",
    "#     roi_day = predict_day(df=df_tweets_for_day, predict_date_str=s.predict_date_str, num_hold_days=s.num_hold_days)\n",
    "#     print(roi_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tweets: 298626\n",
      "Cleaning prediction file...\n",
      "\n",
      "Training and predicting for 2021-02-04 with 3065 rows ...\n",
      "\n",
      "2021-02-05 20:07:19,872 - ams.twitter.twitter_ml_utils - INFO - Finished merging in quarterly stock data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "c:\\programdata\\miniconda3\\envs\\alpha_media_signal\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from statistics import mean\n",
    "from ams.twitter.PredictionParams import TrainParams, PredictionParams, PredictionMode\n",
    "from ams.twitter import pred_persistence\n",
    "\n",
    "df_tiny = df_tweets_ready\n",
    "# df_tiny = df_tweets_ready.sample(frac=.4)\n",
    "\n",
    "def all_the_days(pp: PredictionParams):\n",
    "    print(\"Cleaning prediction file...\")\n",
    "    pred_persistence.clean_prediction_file(pp=pp)\n",
    "\n",
    "    while pp.validate_prediction_date_str():\n",
    "        print(f\"\\nTraining and predicting for {pp.predict_date_str} with {pp.predict_num_rows} rows ...\\n\")\n",
    "\n",
    "        is_complete = twitter_ml_utils.predict_day(pp=pp)\n",
    "        if is_complete:\n",
    "            break\n",
    "\n",
    "        pp.subtract_day()\n",
    "        \n",
    "print(f\"Num tweets: {df_tiny.shape[0]}\")\n",
    "\n",
    "train_params = TrainParams()\n",
    "\n",
    "pred_params = PredictionParams()\n",
    "pred_params.prediction_mode = PredictionMode.RealMoneyStockRecommender\n",
    "pred_params.min_date_str = \"2021-02-04\"\n",
    "pred_params.predict_date_str = \"2021-02-04\"\n",
    "pred_params.max_date_str = pred_params.predict_date_str\n",
    "pred_params.num_hold_days = 5\n",
    "pred_params.df = df_tiny\n",
    "\n",
    "pred_params.clean_pure_run = False\n",
    "pred_params.train_params = train_params\n",
    "\n",
    "all_the_days(pp=pred_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add overall ROI ongoing.(?)\n",
    "# Add EOD (open, close, high, low) to train and predict. But for predict use previous day. Done\n",
    "# Fix SMA: prev day for open for predict, regular for all other dates: Done\n",
    "# Add num days from start - already implemented with day_of_year\n",
    "# Add lookup to previous day's prediction roi - seems to follow on-off-on-off pattern.\n",
    "# Change to WorldTradingDaily real time quotes (12hr) to substitute for open, low, high, and estimate close. (or just take current)\n",
    "# WTD not necessary when using historical.\n",
    "# Test yesterday EOD with 4 day estimate.\n",
    "# Test with historical purchase day eod data (open, close, high, low)\n",
    "# Change SMA back to use purchase day-base SMA.\n",
    "# Reprocess all date with by using sums in Great reduction rather than means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}