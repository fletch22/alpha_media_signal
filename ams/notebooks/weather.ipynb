{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import division\n",
    "import csv, sys, re, timeit, math\n",
    "from sklearn import datasets, linear_model, preprocessing, neural_network\n",
    "from sklearn.utils import column_or_1d\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import dates as mPlotDATEs\n",
    "# helper functions num2date()\n",
    "#                                            #              and date2num()\n",
    "#                                            #              to convert to/from.\n",
    "# http://stackoverflow.com/questions/4090383/plotting-unix-timestamps-in-matplotlib\n",
    "# http://stackoverflow.com/questions/32728212/how-to-plot-timestamps-in-python-using-matplotlib \n",
    "# http://stackoverflow.com/questions/8409095/matplotlib-set-markers-for-individual-points-on-a-line\n",
    "rt_start = timeit.default_timer()\n",
    "\n",
    "# clean log.txt first\n",
    "\n",
    "directory = \"logs\"\n",
    "try:\n",
    "    os.makedirs(directory)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "log_timestr = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "with open(\"logs/log_\" + log_timestr +\".txt\", \"w\") as logfile:\n",
    "    logfile.close()\n",
    "    \n",
    "### functions definition ###\n",
    "def print_data_type(x):\n",
    "    for f in x.columns:\n",
    "        print(\"f = {}\".format(f))\n",
    "        print(x[f].dtype)\n",
    "        \n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def RepresentsFloat(s):\n",
    "    try: \n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def DateToMinute(s, option):\n",
    "    \"\"\"\n",
    "    time delta from the beginning of that year, unit = minutes\n",
    "    s format = '%Y-%m-%d %H:%M'\n",
    "    return type: int\n",
    "    \"\"\"\n",
    "    if (isinstance(s, str) ):\n",
    "        time_obj = datetime.strptime(s, '%Y-%m-%d %H:%M')\n",
    "    elif (isinstance(s, datetime) ):\n",
    "        time_obj = datetime.strptime( s.strftime('%Y-%m-%d %H:%M'), '%Y-%m-%d %H:%M' )\n",
    "    else:\n",
    "        raise SystemError(\"input s is not a valid string/datetime obj!\")\n",
    "        \n",
    "    if (option == 'year'):\n",
    "        time_diff = time_obj - datetime(time_obj.year, 01, 01, 0, 0)\n",
    "    elif (option == 'month'):\n",
    "        time_diff = time_obj - datetime(time_obj.year, time_obj.month, 01, 0, 0)\n",
    "    elif (option == 'day'):\n",
    "        time_diff = time_obj - datetime(time_obj.year, time_obj.month, time_obj.day, 0, 0)\n",
    "    elif (option == 'hour'):\n",
    "        time_diff = time_obj - datetime(time_obj.year, time_obj.month, time_obj.day, time_obj.hour, 0)\n",
    "    else:\n",
    "        raise SystemError(\"option is not a valid string!\")\n",
    "        \n",
    "    return int(time_diff.total_seconds()/60)\n",
    "\n",
    "# do interpolate\n",
    "def interpolate_df(df, features):\n",
    "    df_re = df\n",
    "    \n",
    "    print(\"len(df.index) = {}\".format(len(df.index)))\n",
    "    \n",
    "    # check all the data are float data and change data type to float64\n",
    "    for col in features:\n",
    "        # df[col] = df[col].astype(float)\n",
    "        temp = df[df[col].isnull()]\n",
    "        # print(test.head)\n",
    "        print(\"===\")\n",
    "        # print(test.head(n=1))\n",
    "        print(\"{} type is {}\".format(col, df[col].dtype))\n",
    "        print(\"{} type contain {} np.NaN\".format(col, len(temp.index)))\n",
    "        print(\"===\")\n",
    "    \n",
    "    df_nan = df[ df.isnull().any(axis=1) ]\n",
    "    print(\"len(df_nan.index) = {}\".format(len(df_nan.index)))\n",
    "    # df_nan.to_csv(\"df_nan.csv\")\n",
    "    df_nan.head(n=1)\n",
    "    \n",
    "    print(\"len(df.index) = {}\".format(len(df.index)))\n",
    "    # it could be use time as index and set method = 'time'\n",
    "    # df.to_csv(\"df_before_interpolate.csv\")\n",
    "    # df[features] = df[features].interpolate(method='time')\n",
    "    # df.loc[:, features] = df[features].interpolate(method='time')\n",
    "    # somehow, df(input) will get updated even use inplace=False\n",
    "    df_re.loc[:, features] = df[features].interpolate(method='time', inplace = False)\n",
    "    # df.to_csv(\"df_after_interpolate.csv\")\n",
    "    # print(\"df = \")\n",
    "    # print(df)\n",
    "    \n",
    "    # grab original nan values\n",
    "    df_nan_interpolate = df.loc[ df_nan.index.values ]\n",
    "    print(\"len(df_nan_interpolate.index) = {}\".format(len(df_nan_interpolate.index)))\n",
    "    df_nan_interpolate.to_csv(\"df_nan_interpolate.csv\")\n",
    "    \n",
    "    if (df_re.notnull().all(axis=1).all(axis=0)):\n",
    "        print(\"CHECK: There is no null value in df_re.\")\n",
    "        \n",
    "    return df_re\n",
    "\n",
    "# generate training & test data set\n",
    "def data_gen(df, targets, features, data_tr_yr_start, data_tr_yr_end, data_test_yr_start, data_test_yr_end):\n",
    "    # reset index \n",
    "    # df = df.reset_index(drop=True)\n",
    "    df = df.set_index(\"DATE\")\n",
    "    # prepare training data\n",
    "    data_start = datetime(data_tr_yr_start,  1,  1,  0,  0,  0)\n",
    "    data_end   = datetime(data_tr_yr_end, 12, 31, 23, 59, 59)\n",
    "    df_train = df.loc[(df.index > data_start ) & (df.index <= data_end ), :]\n",
    "    \n",
    "    # do interpolate on training set only\n",
    "    df_train = interpolate_df(df_train, features)\n",
    "    df_train.to_csv('df_train_clean.csv')\n",
    "    \n",
    "    X_train = df_train[features] \n",
    "    y_train = df_train[targets] \n",
    "    \n",
    "    # prepare test data\n",
    "    data_start = datetime(data_test_yr_start,  1,  1,  0,  0,  0)\n",
    "    data_end   = datetime(data_test_yr_end, 12, 31, 23, 59, 59)\n",
    "    df_test = df.loc[(df.index > data_start ) & (df.index <= data_end ), :]\n",
    "    \n",
    "    # drop NaN number rows of test set\n",
    "    (row_old, col_old) = df_test.shape\n",
    "    print(\"Before drop NaN number of test set, df_test.shape = {}\".format(df_test.shape))\n",
    "    df_test = df_test[ df_test.notnull().all(axis=1) ]\n",
    "    (row, col) = df_test.shape\n",
    "    print(\"After drop NaN number of test set, df_test.shape = {}\".format(df_test.shape))\n",
    "    print(\"Drop rate = {0:.2f} \".format(float(1 - (row/row_old)) ) )\n",
    "    \n",
    "    df_test.to_csv('df_test_clean.csv')\n",
    "    X_test = df_test[features] \n",
    "    y_test = df_test[targets] \n",
    "    \n",
    "    # normalization and scale for training/test set\n",
    "    # use robust_scaler to avoid misleading outliers\n",
    "    # scaler = preprocessing.StandardScaler()\n",
    "    # use robust_scaler to avoid misleading outliers\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "    \n",
    "def normalization(df_train, df_test, targets, features):\n",
    "    \n",
    "    # do interpolate on training set only\n",
    "    df_train_local = interpolate_df(df_train, features)\n",
    "    \n",
    "    X_train = df_train_local[features]\n",
    "    y_train = df_train_local[targets] \n",
    "    \n",
    "    X_test = df_test[features] \n",
    "    y_test = df_test[targets]\n",
    "    \n",
    "    # normalization and scale for training/test set\n",
    "    # use robust_scaler to avoid misleading outliers\n",
    "    # scaler = preprocessing.StandardScaler()\n",
    "    # use robust_scaler to avoid misleading outliers\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# plot y_test\n",
    "def plot_y_test(regr, X_test, y_test, ask_user):\n",
    "    (r_test, c_test) = X_test.shape\n",
    "    \n",
    "    # for i in range(c_test):\n",
    "    #     plt.scatter(X_test[:, i], y_test)\n",
    "    #     plt.plot(X_test[:, i], regr.predict(X_test), color='blue', linewidth=3)\n",
    "    \n",
    "    y_predict = regr.predict(X_test)\n",
    "    # print(\"==> y_test type = {}\".format(type(y_test)) )\n",
    "    # print(\"y_test.index = {}\".format(y_test.index))\n",
    "    # print(\"y_test = {}\".format(y_test) )\n",
    "    # print(\"y_predict = {}\".format(y_predict) )\n",
    "    df_plot = y_test\n",
    "    # print(df_plot)\n",
    "    # print(\"DATE\")\n",
    "    # print(\"#########################\")\n",
    "    df_plot = df_plot.reset_index(level=['DATE'])\n",
    "    df_plot.loc[:,'predict_temp_C'] = y_predict\n",
    "    # shift back to raw DATE time 1day_later\n",
    "    df_plot.loc[:,\"raw_DATE\"] = df_plot['DATE'].apply(lambda time_obj: time_obj + relativedelta(days=1))\n",
    "    df_plot.rename(columns={'1days_later_temp_C': 'raw_temp_C', 'DATE':'label_DATE'}, inplace=True)\n",
    "    \n",
    "    df_plot = df_plot.set_index(\"raw_DATE\")\n",
    "    # print(df_plot)\n",
    "    # print(\"#########################\")\n",
    "    \n",
    "    # default plot time range\n",
    "    plot_yr = 2016\n",
    "    plot_month = 10\n",
    "    plot_day = 5 \n",
    "    duration = 10 \n",
    "    \n",
    "    range_start = datetime(plot_yr, plot_month, plot_day, 0, 0, 0)\n",
    "    range_end = datetime(plot_yr, plot_month, plot_day, 0, 0, 0) + relativedelta(days=duration)\n",
    "    \n",
    "    if (range_start < datetime(2016,1,2,0,0,0) or range_end > datetime(2017,1,1,0,0,0) ):\n",
    "        raise SystemExit(\"Input date is out of range! Please try again!\")\n",
    "    else:\n",
    "        print(\"Correct format and time range!\")\n",
    "        \n",
    "    if (ask_user == True):\n",
    "        print(\"Ready to plot! \\n\")\n",
    "        print(\"Time range: 2016/1/2 - 2016/12/31 (duration included) \\n\")\n",
    "        print(\"Please enter the following format (split by comma): \\n\")\n",
    "        print(\"years, month, day, ploting duration(days) \\n\")\n",
    "        print(\"For example, enter: {}, {}, {}, {}\".format(plot_yr, plot_month, plot_day, duration) )\n",
    "        \n",
    "        input_format_ok = False\n",
    "        while(input_format_ok == False):\n",
    "            user_input = input()\n",
    "            print(\"Your input is {}\".format(user_input) )\n",
    "            try:\n",
    "                plot_yr = int(user_input[0]) \n",
    "                plot_month = int(user_input[1]) \n",
    "                plot_day = int(user_input[2]) \n",
    "                duration = int(user_input[3]) \n",
    "                \n",
    "                range_start = datetime(plot_yr, plot_month, plot_day, 0, 0, 0)\n",
    "                range_end = datetime(plot_yr, plot_month, plot_day, 0, 0, 0) + relativedelta(days=duration)\n",
    "                \n",
    "                if (range_start < datetime(2016,1,2,0,0,0) or range_end > datetime(2017,1,1,0,0,0) ):\n",
    "                    print(\"Input date is out of range! Please try again!\")\n",
    "                else:\n",
    "                    print(\"Correct format and time range!\")\n",
    "                    input_format_ok = True\n",
    "            except:\n",
    "                print(\"Incorrect format, please try again!\")\n",
    "    \n",
    "    df_plot = df_plot[range_start.strftime('%Y-%m-%d %H:%M:%S') : range_end.strftime('%Y-%m-%d %H:%M:%S')] \n",
    "    # write to csv file\n",
    "    df_plot_csv_file_name = \"df_plot.csv\"\n",
    "    df_plot.to_csv(df_plot_csv_file_name)\n",
    "    print(\"Prediction start from {} \\n\".format(range_start) )\n",
    "    print(\"Prediction end at {} \\n\".format(range_end) )\n",
    "    print(\"Detail in {}: \\n\".format(df_plot_csv_file_name) )\n",
    "    # print(df_plot)\n",
    "    # dates = [datetime.fromtimestamp(ts) for ts in df_plot.index ]\n",
    "    datenums = [ mPlotDATEs.date2num(ts) for ts in df_plot.index ]\n",
    "    # print(datenums)\n",
    "    # print(mPlotDATEs.num2date(datenums) )\n",
    "    # datenums = mPlotDATEs.date2num(dates)\n",
    "    value_raw = np.array(df_plot['raw_temp_C'])\n",
    "    value_predict = np.array(df_plot['predict_temp_C'])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    # plt.xticks( rotation=25 )\n",
    "    plt.xticks( rotation=60 )\n",
    "    ax=plt.gca()\n",
    "    xfmt = mPlotDATEs.DateFormatter('%Y-%m-%d %H:%M:%S')\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "    ax.xaxis_date()\n",
    "    # plt.scatter(y_test.index, y_test)\n",
    "    # plt.plot(y_test.index, y_predict, color='blue', linewidth=3)\n",
    "    # plt.scatter(y_test.index[0:25], y_test[0:25])\n",
    "    # plt.plot(y_test.index[0:25], y_test[0:25], color='red', linewidth=3)\n",
    "    # plt.plot(y_test.index[0:25], y_predict[0:25], color='blue', linewidth=3)\n",
    "    # plt.subplot(121)\n",
    "    plt.xlabel(\"time range\")\n",
    "    plt.ylabel(\"degree C\")\n",
    "    plt.title(\"raw data (red) v.s. predict data (blue)\") \n",
    "    plt.grid()\n",
    "    plt.plot(datenums, value_raw, linestyle='-', marker='o', markersize=5, color='r', linewidth=2, label=\"raw temp C\")\n",
    "    plt.plot(datenums, value_predict, linestyle='-', marker='o', markersize=5, color='b', linewidth=2, label=\"predict temp C\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    # plt.subplot(122)\n",
    "    plt.xlabel(\"raw data (degree C)\")\n",
    "    plt.ylabel(\"predict data (degree C)\")\n",
    "    plt.title(\"perfect match (red) v.s. model (blue)\") \n",
    "    plt.grid()\n",
    "    plt.plot(value_raw, value_raw, linestyle='--', marker='o', markersize=5, color='r', linewidth=1, label=\"perfect match line\")\n",
    "    plt.scatter(value_raw, value_predict, marker='o', s=10, color='b', label=\"predict temp C\")\n",
    "    # plt.plot(value_predict, marker='o', markersize=3, color='b', label=\"predict temp C\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# poly_degree = int, interaction_only = True\n",
    "def linear_regr(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, model_result):\n",
    "    \n",
    "    # create more features\n",
    "    poly = preprocessing.PolynomialFeatures(poly_degree, interaction_only=interaction_only)\n",
    "    \n",
    "    X_train = poly.fit_transform(X_train) \n",
    "    X_test = poly.fit_transform(X_test)\n",
    "    (s_n, f_n) = X_train.shape\n",
    "    # l_n = int(math.ceil(1.5*f_n))\n",
    "    l_n = int(math.ceil(1.2*f_n))\n",
    "    print(\"@@@ s_n = {}, f_n = {}, l_n = {}\".format(s_n, f_n, l_n) )\n",
    "    \n",
    "    np.savetxt(\"x_train.csv\", X_train, delimiter=\",\")\n",
    "    np.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
    "    np.savetxt(\"x_test.csv\", X_test, delimiter=\",\")\n",
    "    np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")\n",
    "    \n",
    "    print(\"### type of X_train = {}\".format(type(X_train)) )\n",
    "    \n",
    "    # debug\n",
    "    for model in [2]:\n",
    "    # linear regr: [0, 1, 2] NN: [3, 4]\n",
    "    # for model in [0 1 2 3]:\n",
    "    # run all: very long runtime\n",
    "    # for model in [0 1 2 3 4]:\n",
    "        # model selection\n",
    "        ## # test score: 0.83\n",
    "        ## model_name = \"SGDRegressor\"\n",
    "        ## model_rt_start = timeit.default_timer()\n",
    "        ## regr = linear_model.SGDRegressor(penalty='elasticnet', alpha=0.01, l1_ratio=0.25, fit_intercept=True)\n",
    "        ## model_rt_stop = timeit.default_timer()\n",
    "        ## model_runtime = model_rt_stop - model_rt_start \n",
    "        ## # test score: 0.83\n",
    "        ## model_name = \"ElasticNet\"\n",
    "        ## model_rt_start = timeit.default_timer()\n",
    "        ## regr = linear_model.ElasticNet(alpha = 0.01)\n",
    "        ## model_rt_stop = timeit.default_timer()\n",
    "        ## model_runtime = model_rt_stop - model_rt_start \n",
    "        if   (model == 0):\n",
    "            # test score: 0.84\n",
    "            alpha = 0 \n",
    "            model_name = \"linear_model.LinearRegression\"\n",
    "            regr = linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "            model_rt_start = timeit.default_timer()\n",
    "            regr.fit(X_train, column_or_1d(y_train) )\n",
    "            model_rt_stop = timeit.default_timer()\n",
    "            model_runtime = model_rt_stop - model_rt_start \n",
    "            model_result = evaluation(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, \n",
    "                            model_result, model_name, model_runtime, regr, alpha)\n",
    "        elif (model == 1):\n",
    "            for alpha in [0.0001, 0.001, 0.01, 0.1, 1, 3, 10]:\n",
    "                # test score: 0.83\n",
    "                model_name = \"linear_model.Lasso\"\n",
    "                regr_lasso = linear_model.Lasso(alpha = alpha)\n",
    "                model_rt_start = timeit.default_timer()\n",
    "                regr_lasso.fit(X_train, column_or_1d(y_train) )\n",
    "                model_rt_stop = timeit.default_timer()\n",
    "                model_runtime = model_rt_stop - model_rt_start \n",
    "                model_result = evaluation(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, \n",
    "                                model_result, model_name, model_runtime, regr_lasso, alpha)\n",
    "        elif (model == 2):\n",
    "            for alpha in [0.0001, 0.001, 0.01, 0.1, 1, 3, 10]:\n",
    "            # for alpha in [0.0000001, 0.00001, 0.001, 0.01, 0.1, 1, 3, 10, 30, 100, 300, 10**3, 10**4, 10**5]:\n",
    "                # test score: 0.84\n",
    "                model_name = \"linear_model.Ridge\"\n",
    "                regr_ridge = linear_model.Ridge(alpha = alpha)\n",
    "                model_rt_start = timeit.default_timer()\n",
    "                regr_ridge.fit(X_train, column_or_1d(y_train) )\n",
    "                model_rt_stop = timeit.default_timer()\n",
    "                model_runtime = model_rt_stop - model_rt_start \n",
    "                model_result = evaluation(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, \n",
    "                                model_result, model_name, model_runtime, regr_ridge, alpha)\n",
    "        elif (model == 3):\n",
    "            if (poly_degree <= 2):\n",
    "                for alpha in [0.0001, 0.01, 1]:\n",
    "                # for alpha in [0.00001]:\n",
    "                    for layer_n in [3, 7, 11]:\n",
    "                    # for layer_n in [3]:\n",
    "                        # test score: 0.83, runtime longer\n",
    "                        model_name = \"neural_network.MLPRegressor, layer = \" + str(layer_n)\n",
    "                        if(layer_n == 3):\n",
    "                            regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n),alpha=alpha)\n",
    "                        if(layer_n == 7):\n",
    "                            regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n,l_n,l_n,l_n,l_n),alpha=alpha)\n",
    "                        if(layer_n == 11):\n",
    "                            regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n),alpha=alpha)\n",
    "                        model_rt_start = timeit.default_timer()\n",
    "                        regr.fit(X_train, column_or_1d(y_train) )\n",
    "                        model_rt_stop = timeit.default_timer()\n",
    "                        model_runtime = model_rt_stop - model_rt_start \n",
    "                        model_result = evaluation(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, \n",
    "                                        model_result, model_name, model_runtime, regr, alpha)\n",
    "        elif (model == 4):\n",
    "            if (poly_degree <= 3):\n",
    "                for alpha in [1, 10, 1000]:\n",
    "                # for alpha in [0.00001]:\n",
    "                    # for layer_n in [3, 7, 11]:\n",
    "                    for layer_n in [7, 11]:\n",
    "                    # for layer_n in [3]:\n",
    "                        # test score: 0.83, runtime longer\n",
    "                        model_name = \"neural_network.MLPRegressor, layer = \" + str(layer_n)\n",
    "                        if(layer_n == 3):\n",
    "                            regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n),alpha=alpha)\n",
    "                        if(layer_n == 7):\n",
    "                            # regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n,l_n,l_n,l_n,l_n),alpha=alpha)\n",
    "                            regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n,l_n,l_n,l_n,l_n),alpha=alpha, learning_rate='invscaling')\n",
    "                        if(layer_n == 11):\n",
    "                            regr = neural_network.MLPRegressor(random_state=True,hidden_layer_sizes=(l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n,l_n),alpha=alpha)\n",
    "                        model_rt_start = timeit.default_timer()\n",
    "                        regr.fit(X_train, column_or_1d(y_train) )\n",
    "                        model_rt_stop = timeit.default_timer()\n",
    "                        model_runtime = model_rt_stop - model_rt_start \n",
    "                        model_result = evaluation(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, \n",
    "                                        model_result, model_name, model_runtime, regr, alpha)\n",
    "        else:\n",
    "            raise SystemExit(\"Model selection out of range!!!\")\n",
    "        \n",
    "    return model_result\n",
    "\n",
    "def evaluation(X_train, y_train, X_test, y_test, poly_degree, interaction_only, print_coef, plot, ask_user, model_result, model_name, model_runtime, regr, alpha):\n",
    "    print(\"poly_degree = {}, interaction_only = {}\".format(poly_degree, interaction_only))\n",
    "    with open(\"logs/log_\" + log_timestr +\".txt\", \"a\") as logfile:\n",
    "        logfile.write(\"====================\\n\")\n",
    "        logfile.write(\"poly_degree = {}, interaction_only = {}\\n\".format(poly_degree, interaction_only))\n",
    "    \n",
    "    print(\"Model: {} \\n\".format( model_name ) )\n",
    "    print(\"Alpha (Regularization strength): {} \\n\".format( alpha ) )\n",
    "    print(\"X_train.shape = {}\".format(X_train.shape) )\n",
    "    print(\"y_train.shape = {}\".format(y_train.shape) )\n",
    "    print(\"X_test.shape = {}\".format(X_test.shape) )\n",
    "    print(\"y_test.shape = {}\".format(y_test.shape) )\n",
    "    \n",
    "    if (print_coef):\n",
    "        # The coefficients\n",
    "        if hasattr(regr, 'coef_'):\n",
    "            print(\"Coefficients: {}\\n\", regr.coef_)\n",
    "            with open(\"logs/log_\" + log_timestr +\".txt\", \"a\") as logfile:\n",
    "                logfile.write(\"Coefficients: {}\\n\".format(regr.coef_) )\n",
    "        # for neural_network.MLPRegressor\n",
    "        if hasattr(regr, 'coefs_'):\n",
    "            print(\"Coefficients: {}\\n\", regr.coefs_)\n",
    "            with open(\"logs/log_\" + log_timestr +\".txt\", \"a\") as logfile:\n",
    "                logfile.write(\"Coefficients: {}\\n\".format(regr.coefs_) )\n",
    "    \n",
    "    print(\"For training set:\")\n",
    "    (mse_train, score_train) = (0, 0)\n",
    "    # mse_train = float(np.mean( (regr.predict(X_train) - y_train) ** 2) )\n",
    "    # need to use column_or_1d instead of np.array\n",
    "    model_rt_predict_train_start = timeit.default_timer()\n",
    "    predict_train = regr.predict(X_train)\n",
    "    model_rt_predict_train_stop = timeit.default_timer()\n",
    "    model_runtime_predict_train = model_rt_predict_train_stop - model_rt_predict_train_start\n",
    "    mse_train = float( np.mean( (predict_train - column_or_1d(y_train) ) ** 2) )\n",
    "    score_train = regr.score(X_train, y_train)\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error (train): {0:.3f} \\n\".format( mse_train ) )\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print(\"Variance score (train): {0:.3f} \\n\".format( score_train ) )\n",
    "    print(\"model_runtime (training) = {0:.3f} (seconds) \\n\".format(model_runtime))\n",
    "    print(\"model_runtime (predict train set) = {0:.3f} (seconds) \\n\".format(model_runtime_predict_train))\n",
    "    \n",
    "    print(\"For test set:\")\n",
    "    (mse_test, score_test) = (0, 0)\n",
    "    model_rt_predict_test_start = timeit.default_timer()\n",
    "    predict_test = regr.predict(X_test)\n",
    "    model_rt_predict_test_stop = timeit.default_timer()\n",
    "    model_runtime_predict_test = model_rt_predict_test_stop - model_rt_predict_test_start\n",
    "    mse_test = float(np.mean( (predict_test - column_or_1d(y_test) ) ** 2) )\n",
    "    score_test = regr.score(X_test, y_test)\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error (test): {0:.3f} \\n\".format( mse_test ) )\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print(\"Variance score (test): {0:.3f} \\n\".format( score_test ) )\n",
    "    print(\"model_runtime (predict test set) = {0:.3f} (seconds) \\n\".format(model_runtime_predict_test))\n",
    "    \n",
    "    with open(\"logs/log_\" + log_timestr +\".txt\", \"a\") as logfile:\n",
    "        logfile.write(\"====================\\n\")\n",
    "        logfile.write(\"Features polynomial degree: {} \\n\".format( poly_degree ) )\n",
    "        logfile.write(\"Model: {} \\n\".format( model_name ) )\n",
    "        logfile.write(\"Alpha (Regularization strength): {} \\n\".format( alpha ) )\n",
    "        logfile.write(\"X_train.shape = {} \\n\".format(X_train.shape) )\n",
    "        logfile.write(\"y_train.shape = {} \\n\".format(y_train.shape) )\n",
    "        logfile.write(\"X_test.shape = {} \\n\".format(X_test.shape) )\n",
    "        logfile.write(\"y_test.shape = {} \\n\".format(y_test.shape) )\n",
    "        logfile.write(\"For training set: \\n\")\n",
    "        logfile.write(\"Mean squared error (train): {0:.3f} \\n\".format( mse_train ) )\n",
    "        logfile.write(\"Variance score (train): {0:.3f} \\n\".format( score_train ) )\n",
    "        logfile.write(\"For test set: \\n\")\n",
    "        logfile.write(\"Mean squared error (test): {0:.3f} \\n\".format( mse_test ) )\n",
    "        logfile.write(\"Variance score (test): {0:.3f} \\n\".format( score_test ) )\n",
    "        logfile.write(\"model_runtime (training) = {0:.3f} (seconds) \\n\".format(model_runtime))\n",
    "        logfile.write(\"model_runtime (predict train set) = {0:.3f} (seconds) \\n\".format(model_runtime_predict_train))\n",
    "        logfile.write(\"model_runtime (predict test set) = {0:.3f} (seconds) \\n\".format(model_runtime_predict_test))\n",
    "        logfile.write(\"====================\\n\")\n",
    "    \n",
    "    # collect info.\n",
    "    (s_n, f_n) = X_train.shape\n",
    "    model_result.update({(model_name, alpha, int(f_n), poly_degree ):[]})\n",
    "    ## model_result[(model_name, alpha, int(f_n) )] = ( poly_degree, round(mse_train, 3), round(score_train, 3), \n",
    "    ##             round(mse_test, 3), round(score_test, 3), \n",
    "    ##             round(model_runtime, 3), round(model_runtime_predict_train, 3), round(model_runtime_predict_test, 3) )\n",
    "    model_result[(model_name, alpha, int(f_n), poly_degree )] = ( round(mse_train, 3), round(score_train, 3), \n",
    "                round(mse_test, 3), round(score_test, 3), \n",
    "                round(model_runtime, 3), round(model_runtime_predict_train, 3), round(model_runtime_predict_test, 3) )\n",
    "    \n",
    "    # print shape\n",
    "    if (plot == True):\n",
    "        plot_y_test(regr, X_test, y_test, ask_user)\n",
    "    \n",
    "    return model_result\n",
    "\n",
    "\n",
    "# def run_fit(postfix, df_run, targets_run, features_run, poly_d_max, inter_only, print_coef, plot):\n",
    "def run_fit(postfix, df_run_train, df_run_test, targets_run, features_run, poly_d_max, inter_only, print_coef, plot, ask_user):\n",
    "    text = \"RUNNING... df\" + postfix\n",
    "    print(\"{0:{fill}{align}16}\".format(text, fill='=', align='^'))\n",
    "    (X_train, y_train, X_test, y_test) = (0, 0, 0, 0) \n",
    "    # (X_train, y_train, X_test, y_test) = data_gen(df_run, targets_run, features_run, 2006, 2015, 2016, 2016)\n",
    "    (X_train, y_train, X_test, y_test) = normalization(df_run_train, df_run_test, targets_run, features_run)\n",
    "    # data = []\n",
    "    # (data[0], data[1], data[2], data[3]) = data_gen(df_run, features_run)\n",
    "    print(\"df{} X_train.shape = {}\".format(postfix, X_train.shape))\n",
    "    print(\"df{} y_train.shape = {}\".format(postfix, y_train.shape))\n",
    "    print(\"df{} X_test.shape = {}\".format(postfix, X_test.shape))\n",
    "    print(\"df{} y_test.shape = {}\".format(postfix, y_test.shape))\n",
    "    print(\"df_run_train target + features = {}\".format(df_run_train.columns.values))\n",
    "    print(\"=====\")\n",
    "    \n",
    "    model_re = {}\n",
    "    \n",
    "    # for poly_d in range(1, poly_d_max+1):\n",
    "    for poly_d in range(1, poly_d_max+1):\n",
    "        model_re = linear_regr(X_train, y_train, X_test, y_test, poly_degree = poly_d, \n",
    "            interaction_only = inter_only, print_coef = print_coef, plot = plot, ask_user = ask_user, model_result = model_re)\n",
    "    return model_re\n",
    "\n",
    "def create_new_features(df):\n",
    "    if (\"DATE\" in df.columns):\n",
    "        df[\"mins_year\"] = df[\"DATE\"].apply(lambda x : DateToMinute(x, 'year'))\n",
    "        df[\"mins_month\"] = df[\"DATE\"].apply(lambda x : DateToMinute(x, 'month'))\n",
    "        df[\"mins_day\"] = df[\"DATE\"].apply(lambda x : DateToMinute(x, 'day'))\n",
    "        df[\"mins_hour\"] = df[\"DATE\"].apply(lambda x : DateToMinute(x, 'hour'))\n",
    "        \n",
    "        # cos function for seasonal features\n",
    "        df[\"cos_mins_year\"] = df[\"mins_year\"].apply(lambda x : math.cos( math.radians( (x/(366*24*60))*360 )) )\n",
    "        df[\"cos_mins_month\"] = df[\"mins_month\"].apply(lambda x : math.cos( math.radians( (x/(31*24*60))*360 )) )\n",
    "        df[\"cos_mins_day\"] = df[\"mins_day\"].apply(lambda x : math.cos( math.radians( (x/(1*24*60))*360 )) )\n",
    "    \n",
    "    if (\"HOURLYWindDirection\" in df.columns):\n",
    "        # wind direction normalization\n",
    "        df[\"cos_wind_dir\"] = df[\"HOURLYWindDirection\"].apply(lambda x : math.cos( math.radians(x) ) )\n",
    "    \n",
    "    return df\n",
    "\n",
    "### end of functions definition ###\n",
    "\n",
    "st = ['STATION']\n",
    "targets = ['HOURLYDRYBULBTEMPC']\n",
    "date = ['DATE']\n",
    "\n",
    "# removing \n",
    "# 'HOURLYVISIBILITY' (no influence) & \n",
    "# 'HOURLYSeaLevelPressure' (around 1/10 empty data), no influence\n",
    "# 'HOURLYPrecip' (no influence & many empty data)\n",
    "# selective original features\n",
    "# s_features = [] \n",
    "s_features = ['HOURLYDewPointTempC', 'HOURLYRelativeHumidity', 'HOURLYWindSpeed', 'HOURLYWindDirection', 'HOURLYStationPressure']\n",
    "# s_features = ['HOURLYRelativeHumidity', 'HOURLYWindSpeed', 'HOURLYWindDirection', 'HOURLYStationPressure']\n",
    "# s_features = ['HOURLYRelativeHumidity', 'HOURLYWindSpeed', 'HOURLYWindDirection']\n",
    "\n",
    "## # original selected features (excluding targets & date)\n",
    "## features = ['HOURLYVISIBILITY', 'HOURLYDewPointTempC', 'HOURLYRelativeHumidity', 'HOURLYWindSpeed', \n",
    "##             'HOURLYWindDirection', 'HOURLYStationPressure', 'HOURLYSeaLevelPressure', 'HOURLYPrecip']\n",
    "\n",
    "# df = pd.read_csv('weather_2_stations.csv', parse_dates=['DATE'])\n",
    "# df = pd.read_csv('weather_2_stations.csv', dtype=date_type, na_values=additional_na_v, parse_dates=['DATE'])\n",
    "\n",
    "test = ['cos_wind_dir']\n",
    "features_test_only = test\n",
    "# create seasonal related features\n",
    "features_seasonal_only = ['mins_year', 'mins_day', 'cos_mins_year', 'cos_mins_day']\n",
    "# features_seasonal_only = ['mins_year', 'mins_day', 'cos_wind_dir']\n",
    "# features_seasonal_only = ['cos_mins_year', 'cos_mins_day', 'cos_wind_dir']\n",
    "features_seasonal_test = features_seasonal_only + test\n",
    "\n",
    "features_no_time_no_test = [x for x in s_features if x not in test] \n",
    "features_no_test = [x for x in (s_features+features_seasonal_only) if x not in test] \n",
    "features_no_time = [x for x in s_features if x not in features_seasonal_only] \n",
    "\n",
    "fields = st + targets + date + s_features\n",
    "\n",
    "## df = pd.read_csv('weather_2_stations.csv', usecols=fields, parse_dates=date)\n",
    "df = pd.read_csv('station_1.csv', usecols=fields, parse_dates=date)\n",
    "s1 = df[ df.STATION == 'WBAN:23244' ]\n",
    "s2 = df[ df.STATION == 'WBAN:23293' ]\n",
    "\n",
    "# s1.to_csv('s1.csv')\n",
    "# s2.to_csv('s2.csv')\n",
    "\n",
    "# station = pd.read_csv('s1.csv', parse_dates=['DATE'])\n",
    "# station = pd.read_csv('s2.csv', parse_dates=['DATE'])\n",
    "\n",
    "del df\n",
    "df = s2[targets + s_features]\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df = df.assign( DATE = s2[date])\n",
    "df = create_new_features(df)\n",
    "\n",
    "# debug\n",
    "for experiment in [3]:\n",
    "# for experiment in [0]:\n",
    "# for experiment in [0,1,2,3]:\n",
    "\n",
    "    if   (experiment == 0):\n",
    "        new_features = targets\n",
    "    elif (experiment == 1):\n",
    "        new_features = targets + s_features + features_test_only\n",
    "    elif (experiment == 2):\n",
    "        new_features = targets + features_seasonal_only\n",
    "    elif (experiment == 3):\n",
    "        new_features = targets + s_features + features_test_only + features_seasonal_only\n",
    "    else:\n",
    "        raise sys.SystemExit(\"new_features is out of range!!!\")\n",
    "    \n",
    "    print(\"len(df.index) = {}\".format(len(df.index)))\n",
    "    \n",
    "    # default training yr\n",
    "    # HOURLYStationPressure data start at 2005 for station, WBAN:23293\n",
    "    ## train_yr_start = 2005\n",
    "    ## station_1.csv 2007.01.01 - 2016.12.31\n",
    "    train_yr_start = 2007\n",
    "    train_years = 9 \n",
    "    test_years = 1\n",
    "    # train_yr_start = 2006\n",
    "    # train_years = 10\n",
    "    # test_years = 1\n",
    "    test_yr_start = train_yr_start + train_years \n",
    "     \n",
    "    \n",
    "    # score: 0.68\n",
    "    # days_later = 365\n",
    "    # score: 0.69 \n",
    "    # days_later = 30 \n",
    "    # score: 0.86\n",
    "    days_later = 1\n",
    "    \n",
    "    # select month, select day\n",
    "    if(days_later == 365):\n",
    "        # fixed date\n",
    "        (s_month, s_day) = (1, 1)\n",
    "    elif(days_later == 30):\n",
    "        # s_month: 1 - 11\n",
    "        (s_month, s_day) = (3, 1)\n",
    "    elif(days_later == 1):\n",
    "        # (s_month, s_day) = (6, 1)\n",
    "        (s_month, s_day) = (1, 1)\n",
    "    else:\n",
    "        raise SystemExit(\"Please enter a valid days_later: 365/30/1.\")\n",
    "    \n",
    "    new_target = [str(days_later)+\"days_later_temp_C\"]\n",
    "    # http://stackoverflow.com/questions/25322933/pandas-timeseries-comparison\n",
    "    # new_features = targets + features_seasonal_test \n",
    "    # df1 = df[date + targets + features_seasonal_test]\n",
    "    # df2 = df[date + targets + features_seasonal_test]\n",
    "    # poly_degree = 3, interaction_only = False\n",
    "    # Mean squared error: 9.63\n",
    "    # Variance score: 0.66 \n",
    "    \n",
    "    df1 = df[date + new_features]\n",
    "    df2 = df[date + new_features]\n",
    "    \n",
    "    df2.loc[:,\"DATE\"] = df1[\"DATE\"].apply(lambda time_obj: time_obj + relativedelta(days=-days_later))\n",
    "    df2.rename(columns={str(targets[0]):str(new_target[0])}, inplace=True)\n",
    "    \n",
    "    df1 = df1.set_index([\"DATE\"])\n",
    "    df2 = df2.set_index([\"DATE\"])\n",
    "    # df2 = df2.set_index([new_target])\n",
    "    \n",
    "    t1, t2 = df1.align(df2)\n",
    "    \n",
    "    t3 = t1\n",
    "    t3.loc[:, new_target] = t2[new_target]\n",
    "    # df_time_train = t3['2006':'2014']\n",
    "    range_start = datetime(train_yr_start, 1, 1, 0, 0, 0)\n",
    "    range_end   = datetime(train_yr_start, 1, 1, 0, 0, 0) + relativedelta(years=train_years)\n",
    "    \n",
    "    df_time_train = t3[range_start.strftime('%Y-%m-%d %H:%M:%S') : range_end.strftime('%Y-%m-%d %H:%M:%S')] \n",
    "    print(\"df_time_train.shape = {}\".format(df_time_train.shape))\n",
    "    df_time_train.loc[:, new_target] = df_time_train[new_target].interpolate(method='time')\n",
    "    \n",
    "    # df_time_test = t3['2015'] \n",
    "    range_start = datetime(test_yr_start, s_month, s_day, 0, 0, 0)\n",
    "    range_end   = datetime(test_yr_start, s_month, s_day, 0, 0, 0) + relativedelta(days=365)\n",
    "    # range_end   = datetime(2017, 3, 05, 0, 0, 0)\n",
    "    # range_end   = datetime(2017, 3, 05, 0, 0, 0)\n",
    "    \n",
    "    df_time_test = t3[range_start.strftime('%Y-%m-%d %H:%M:%S') : range_end.strftime('%Y-%m-%d %H:%M:%S')] \n",
    "    print(\"df_time_test.shape = {}\".format(df_time_train.shape))\n",
    "    \n",
    "    # drop NaN number rows of test set\n",
    "    (row_old, col_old) = df_time_test.shape\n",
    "    print(\"Before drop NaN number of test set, df_time_test.shape = {}\".format(df_time_test.shape))\n",
    "    df_time_test = df_time_test[ df_time_test.notnull().all(axis=1) ]\n",
    "    (row, col) = df_time_test.shape\n",
    "    print(\"After drop NaN number of test set, df_time_test.shape = {}\".format(df_time_test.shape))\n",
    "    print(\"Drop rate = {0:.2f} \".format(float(1 - (row/row_old)) ) )\n",
    "    \n",
    "    print(\"===================== \\n\")\n",
    "    print(\"### Experiment = {} \\n\".format( experiment ) )\n",
    "    print(\"new_target = {} \\n\".format( new_target ) )\n",
    "    print(\"new_features = {} \\n\".format( new_features ) )\n",
    "    with open(\"logs/log_\" + log_timestr +\".txt\", \"a\") as logfile:\n",
    "        logfile.write(\"===================== \\n\")\n",
    "        logfile.write(\"### Experiment = {} \\n\".format( experiment ) )\n",
    "        logfile.write(\"new_target = {} \\n\".format( new_target ) )\n",
    "        logfile.write(\"new_features = {} \\n\".format( new_features ) )\n",
    "    # run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=3, inter_only=False, print_coef=False, plot=False, ask_user=False)\n",
    "    # run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=2, inter_only=False, print_coef=True, plot=False, ask_user=False)\n",
    "    # ask_user = False (using default)\n",
    "    # run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=1, inter_only=False, print_coef=True, plot=True, ask_user=False)\n",
    "    # model_re = run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=3, inter_only=False, print_coef=False, plot=False, ask_user=False)\n",
    "    # model_re = run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=2, inter_only=False, print_coef=False, plot=False, ask_user=False)\n",
    "    model_re = run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=2, inter_only=False, print_coef=False, plot=True, ask_user=False)\n",
    "    # ask_user = True (asking user for ploting time range)\n",
    "    # run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=2, inter_only=False, print_coef=True, plot=True, ask_user=True)\n",
    "    # debug \n",
    "    # run_fit(\"_predict_\", df_time_train, df_time_test, new_target, new_features, poly_d_max=1, inter_only=False, print_coef=True, plot=False, ask_user=False)\n",
    "    \n",
    "    print(\"### Experiment = {} \\n\".format( experiment ) )\n",
    "    # print(\"model_re = {}\".format(model_re))\n",
    "    \n",
    "    rt_stop = timeit.default_timer()\n",
    "    total_runtime = rt_stop - rt_start\n",
    "    print(\"runtime = {} (seconds) \\n\".format(total_runtime))\n",
    "    with open(\"logs/log_\" + log_timestr +\".txt\", \"a\") as logfile:\n",
    "        logfile.write(\"total runtime = {} (seconds) \\n\".format(total_runtime))\n",
    "        logfile.write(\"### Experiment = {} \\n\".format( experiment ) )\n",
    "        for i in model_re.keys():\n",
    "            # logfile.write(\"=== model result === \\n\")\n",
    "            logfile.write(\"model_re[{}] = {}\\n\".format(i, model_re[i]))\n",
    "            # logfile.write(\"{} \\n\".format(model_re[i]))\n",
    "            # logfile.write(\"==================== \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}